{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (27401, 64, 64) (27401, 6)\n",
      "Validation set (6000, 64, 64) (6000, 6)\n",
      "Test set (13068, 64, 64) (13068, 6)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'SVHN_multi_crop.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def accuracy_single(predictions, labels):\n",
    "    \"\"\"calculate character-level accuracy\"\"\"\n",
    "    a = np.argmax(predictions, 2).T == labels[:,1:6]\n",
    "    length = labels[:,0]\n",
    "    summ = 0.0\n",
    "    for i in range(len(length)):\n",
    "        summ += np.sum(a[i,:length[i]])\n",
    "    return(100 * summ / np.sum(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_multi(predictions, labels):\n",
    "    \"\"\"calculate sequence-level accuracy\"\"\"\n",
    "    count = predictions.shape[1]\n",
    "    return 100.0 * (count - np.sum([1 for i in np.argmax(predictions, 2).T == labels[:,1:6] if False in i])) / count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, BatchNormalization, Dropout, Flatten\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    # keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(64, 64, 1)),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    # 512 neuron hidden layer\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dense(6, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20001\n",
      "857/857 [==============================] - 225s 263ms/step - loss: 71.9343 - accuracy: 0.0314 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 2/20001\n",
      "857/857 [==============================] - 195s 227ms/step - loss: 72.0676 - accuracy: 0.0292 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 3/20001\n",
      "857/857 [==============================] - 195s 227ms/step - loss: 71.9954 - accuracy: 0.0291 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 4/20001\n",
      "857/857 [==============================] - 204s 238ms/step - loss: 72.0448 - accuracy: 0.0311 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 5/20001\n",
      "857/857 [==============================] - 205s 239ms/step - loss: 72.0194 - accuracy: 0.0301 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 6/20001\n",
      "857/857 [==============================] - 239s 278ms/step - loss: 72.1242 - accuracy: 0.0271 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 7/20001\n",
      "857/857 [==============================] - 206s 241ms/step - loss: 72.0164 - accuracy: 0.0296 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 8/20001\n",
      "857/857 [==============================] - 259s 302ms/step - loss: 72.0826 - accuracy: 0.0286 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 9/20001\n",
      "857/857 [==============================] - 266s 310ms/step - loss: 71.9788 - accuracy: 0.0292 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 10/20001\n",
      "857/857 [==============================] - 265s 309ms/step - loss: 71.9972 - accuracy: 0.0287 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 11/20001\n",
      "857/857 [==============================] - 267s 311ms/step - loss: 71.9728 - accuracy: 0.0285 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 12/20001\n",
      "857/857 [==============================] - 256s 299ms/step - loss: 72.0127 - accuracy: 0.0292 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 13/20001\n",
      "857/857 [==============================] - 2404s 3s/step - loss: 72.0719 - accuracy: 0.0286 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 14/20001\n",
      "857/857 [==============================] - 580s 677ms/step - loss: 71.9398 - accuracy: 0.0296 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 15/20001\n",
      "857/857 [==============================] - 660s 770ms/step - loss: 71.9871 - accuracy: 0.0300 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 16/20001\n",
      "857/857 [==============================] - 656s 766ms/step - loss: 72.0325 - accuracy: 0.0289 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 17/20001\n",
      "857/857 [==============================] - 655s 764ms/step - loss: 71.9264 - accuracy: 0.0296 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 18/20001\n",
      "857/857 [==============================] - 662s 773ms/step - loss: 71.9598 - accuracy: 0.0294 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 19/20001\n",
      "857/857 [==============================] - 660s 770ms/step - loss: 71.9102 - accuracy: 0.0310 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 20/20001\n",
      "857/857 [==============================] - 10434s 12s/step - loss: 72.0231 - accuracy: 0.0279 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 21/20001\n",
      "857/857 [==============================] - 220s 257ms/step - loss: 72.0412 - accuracy: 0.0303 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 22/20001\n",
      "857/857 [==============================] - 213s 248ms/step - loss: 71.9803 - accuracy: 0.0271 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 23/20001\n",
      "857/857 [==============================] - 209s 243ms/step - loss: 72.0328 - accuracy: 0.0288 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 24/20001\n",
      "857/857 [==============================] - 204s 238ms/step - loss: 71.9959 - accuracy: 0.0304 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 25/20001\n",
      "857/857 [==============================] - 204s 238ms/step - loss: 71.9698 - accuracy: 0.0281 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 26/20001\n",
      "857/857 [==============================] - 224s 262ms/step - loss: 71.9005 - accuracy: 0.0291 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 27/20001\n",
      "857/857 [==============================] - 8192s 10s/step - loss: 72.0729 - accuracy: 0.0301 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 28/20001\n",
      "857/857 [==============================] - 222s 260ms/step - loss: 71.9937 - accuracy: 0.0307 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 29/20001\n",
      "857/857 [==============================] - 259s 303ms/step - loss: 72.1333 - accuracy: 0.0281 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 30/20001\n",
      "857/857 [==============================] - 244s 284ms/step - loss: 72.1145 - accuracy: 0.0275 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 31/20001\n",
      "857/857 [==============================] - 213s 249ms/step - loss: 72.0235 - accuracy: 0.0296 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 32/20001\n",
      "857/857 [==============================] - 212s 247ms/step - loss: 71.9715 - accuracy: 0.0284 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 33/20001\n",
      "857/857 [==============================] - 207s 241ms/step - loss: 72.0734 - accuracy: 0.0284 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 34/20001\n",
      "857/857 [==============================] - 210s 245ms/step - loss: 71.9068 - accuracy: 0.0295 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 35/20001\n",
      "857/857 [==============================] - 221s 258ms/step - loss: 72.0546 - accuracy: 0.0288 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 36/20001\n",
      "857/857 [==============================] - 207s 241ms/step - loss: 72.0196 - accuracy: 0.0310 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 37/20001\n",
      "857/857 [==============================] - 204s 238ms/step - loss: 71.9065 - accuracy: 0.0284 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 38/20001\n",
      "857/857 [==============================] - 202s 236ms/step - loss: 72.0315 - accuracy: 0.0291 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 39/20001\n",
      "857/857 [==============================] - 208s 243ms/step - loss: 72.1228 - accuracy: 0.0293 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 40/20001\n",
      "857/857 [==============================] - 215s 250ms/step - loss: 71.9906 - accuracy: 0.0298 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 41/20001\n",
      "857/857 [==============================] - 211s 246ms/step - loss: 72.0920 - accuracy: 0.0289 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 42/20001\n",
      "857/857 [==============================] - 255s 298ms/step - loss: 72.0243 - accuracy: 0.0292 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 43/20001\n",
      "857/857 [==============================] - 251s 292ms/step - loss: 72.1198 - accuracy: 0.0279 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 44/20001\n",
      "857/857 [==============================] - 275s 320ms/step - loss: 71.9983 - accuracy: 0.0297 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 45/20001\n",
      "857/857 [==============================] - 292s 341ms/step - loss: 72.0487 - accuracy: 0.0295 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 46/20001\n",
      "857/857 [==============================] - 279s 326ms/step - loss: 72.0230 - accuracy: 0.0283 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 47/20001\n",
      "857/857 [==============================] - 295s 345ms/step - loss: 71.9561 - accuracy: 0.0293 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 48/20001\n",
      "857/857 [==============================] - 269s 314ms/step - loss: 72.0076 - accuracy: 0.0277 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 49/20001\n",
      "857/857 [==============================] - 289s 337ms/step - loss: 72.0071 - accuracy: 0.0310 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 50/20001\n",
      "857/857 [==============================] - 300s 350ms/step - loss: 71.9809 - accuracy: 0.0291 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 51/20001\n",
      "857/857 [==============================] - 239s 279ms/step - loss: 72.0217 - accuracy: 0.0299 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 52/20001\n",
      "857/857 [==============================] - 243s 283ms/step - loss: 71.9723 - accuracy: 0.0297 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 53/20001\n",
      "857/857 [==============================] - 220s 257ms/step - loss: 72.0105 - accuracy: 0.0304 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 54/20001\n",
      "857/857 [==============================] - 223s 261ms/step - loss: 72.0277 - accuracy: 0.0287 - val_loss: 72.0854 - val_accuracy: 0.0300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/20001\n",
      "857/857 [==============================] - 226s 264ms/step - loss: 72.0210 - accuracy: 0.0287 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 56/20001\n",
      "857/857 [==============================] - 245s 285ms/step - loss: 72.0405 - accuracy: 0.0304 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 57/20001\n",
      "857/857 [==============================] - 231s 270ms/step - loss: 72.0283 - accuracy: 0.0294 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 58/20001\n",
      "857/857 [==============================] - 199s 232ms/step - loss: 72.0335 - accuracy: 0.0278 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 59/20001\n",
      "857/857 [==============================] - 199s 233ms/step - loss: 71.9896 - accuracy: 0.0311 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 60/20001\n",
      "857/857 [==============================] - 915s 1s/step - loss: 72.0967 - accuracy: 0.0291 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 61/20001\n",
      "857/857 [==============================] - 199s 232ms/step - loss: 72.0924 - accuracy: 0.0288 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 62/20001\n",
      "857/857 [==============================] - 197s 230ms/step - loss: 72.0179 - accuracy: 0.0299 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 63/20001\n",
      "857/857 [==============================] - 197s 230ms/step - loss: 72.0618 - accuracy: 0.0305 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 64/20001\n",
      "857/857 [==============================] - 194s 227ms/step - loss: 71.9607 - accuracy: 0.0290 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 65/20001\n",
      "857/857 [==============================] - 674s 786ms/step - loss: 72.0418 - accuracy: 0.0282 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 66/20001\n",
      "857/857 [==============================] - 208s 243ms/step - loss: 71.9265 - accuracy: 0.0290 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 67/20001\n",
      "857/857 [==============================] - 215s 251ms/step - loss: 71.9999 - accuracy: 0.0288 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 68/20001\n",
      "857/857 [==============================] - 197s 230ms/step - loss: 72.0164 - accuracy: 0.0309 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 69/20001\n",
      "857/857 [==============================] - 188s 220ms/step - loss: 72.0351 - accuracy: 0.0280 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 70/20001\n",
      "857/857 [==============================] - 190s 222ms/step - loss: 72.0180 - accuracy: 0.0308 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 71/20001\n",
      "857/857 [==============================] - 191s 223ms/step - loss: 71.9171 - accuracy: 0.0291 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 72/20001\n",
      "857/857 [==============================] - 190s 222ms/step - loss: 71.9424 - accuracy: 0.0305 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 73/20001\n",
      "857/857 [==============================] - 211s 246ms/step - loss: 71.9617 - accuracy: 0.0297 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 74/20001\n",
      "857/857 [==============================] - 211s 247ms/step - loss: 71.9352 - accuracy: 0.0291 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 75/20001\n",
      "857/857 [==============================] - 203s 237ms/step - loss: 72.0259 - accuracy: 0.0291 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 76/20001\n",
      "857/857 [==============================] - 204s 238ms/step - loss: 72.0784 - accuracy: 0.0275 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 77/20001\n",
      "857/857 [==============================] - 212s 247ms/step - loss: 72.0841 - accuracy: 0.0286 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 78/20001\n",
      "857/857 [==============================] - 199s 232ms/step - loss: 72.0709 - accuracy: 0.0292 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 79/20001\n",
      "857/857 [==============================] - 213s 249ms/step - loss: 72.1589 - accuracy: 0.0258 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 80/20001\n",
      "857/857 [==============================] - 219s 256ms/step - loss: 71.9626 - accuracy: 0.0307 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 81/20001\n",
      "857/857 [==============================] - 211s 247ms/step - loss: 72.0056 - accuracy: 0.0301 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 82/20001\n",
      "857/857 [==============================] - 208s 243ms/step - loss: 71.9723 - accuracy: 0.0287 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 83/20001\n",
      "857/857 [==============================] - 209s 244ms/step - loss: 71.9336 - accuracy: 0.0304 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 84/20001\n",
      "857/857 [==============================] - 209s 244ms/step - loss: 72.1958 - accuracy: 0.0281 - val_loss: 72.0854 - val_accuracy: 0.0300\n",
      "Epoch 85/20001\n",
      "324/857 [==========>...................] - ETA: 2:20 - loss: 71.9346 - accuracy: 0.0302"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-57a4842f9d4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 _r=1):\n\u001b[1;32m   1101\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2920\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2921\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2922\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2924\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1857\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1932\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1934\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1935\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1936\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    555\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_dataset = train_dataset[...,np.newaxis]\n",
    "valid_dataset = valid_dataset[...,np.newaxis]\n",
    "model.fit(\n",
    "  train_dataset, train_labels,\n",
    "  batch_size=batch_size,\n",
    "  validation_data=(valid_dataset, valid_labels),\n",
    "  epochs=20001\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conv_1 :             28 * 28 * 16  \n",
    "max pooling:         14 * 14 * 16  \n",
    "conv_2:              10 * 10 * 32  \n",
    "max_pooling:         5 * 5 * 32  \n",
    "conv_3:              1 * 1 * 64  \n",
    "\n",
    "dropout              0.9375  \n",
    "sw_1:                64 * 11  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5\n",
    "depth1 = 16\n",
    "depth2 = 32\n",
    "depth3 = 64\n",
    "num_hidden = 64\n",
    "\n",
    "image_size = 32\n",
    "num_labels = 11 \n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    def weight_variable(shape):\n",
    "        initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(1.0, shape = shape)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def conv2d(data, weight):\n",
    "        # strides [1, x_movement, y_movement, 1]\n",
    "        return tf.nn.conv2d(data, weight, strides = [1, 1, 1, 1], padding = 'VALID')\n",
    "\n",
    "    def max_pooling(data):\n",
    "        return tf.nn.max_pool(data, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    \n",
    "    \n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 6))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    \n",
    "    # Varibles\n",
    "    # conv1 layer 1\n",
    "#     layer1_weights = weight_varible([patch_size, patch_size, num_channels, depth1])\n",
    "    layer1_weights = tf.get_variable('W1',shape=[patch_size, patch_size, num_channels, depth1],\\\n",
    "                                     initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    layer1_biases = bias_variable([depth1]) # 16\n",
    "    # conv2 layer 2\n",
    "#     layer2_weights = weight_varible([patch_size, patch_size, depth1, depth2]) # in depth1, out depth2\n",
    "    layer2_weights = tf.get_variable('W2',shape=[patch_size, patch_size, depth1, depth2],\\\n",
    "                                     initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    layer2_biases = bias_variable([depth2]) # 32\n",
    "    # conv3 layer 3\n",
    "#     layer3_weights = weight_varible([patch_size, patch_size, depth2, depth3]) # in depth2, out depth3\n",
    "    layer3_weights = tf.get_variable('W3',shape=[patch_size, patch_size, depth2, depth3],\\\n",
    "                                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "    layer3_biases = bias_variable([depth3]) # 64\n",
    "    \n",
    "\n",
    "    s1_w = tf.get_variable(\"WS1\", shape=[num_hidden, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    s1_b = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='BS1')\n",
    "    s2_w = tf.get_variable(\"WS2\", shape=[num_hidden, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    s2_b = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='BS2')\n",
    "    s3_w = tf.get_variable(\"WS3\", shape=[num_hidden, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    s3_b = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='BS3')\n",
    "    s4_w = tf.get_variable(\"WS4\", shape=[num_hidden, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    s4_b = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='BS4')\n",
    "    s5_w = tf.get_variable(\"WS5\", shape=[num_hidden, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    s5_b = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='BS5')\n",
    "    \n",
    "    sw = [s1_w, s2_w, s3_w, s4_w, s5_w]\n",
    "    \n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    \n",
    "    def model(dataset):\n",
    "        # conv1 layer 1\n",
    "        hidden1 = tf.nn.relu(conv2d(dataset, layer1_weights) + layer1_biases) # 28 * 28 * depth1\n",
    "        pool1 = max_pooling(hidden1) # 14 * 14 * depth1\n",
    "        # conv2 layer 2\n",
    "        hidden2 = tf.nn.relu(conv2d(pool1, layer2_weights) + layer2_biases) # 10 * 10 * depth2\n",
    "        pool2 = max_pooling(hidden2) # 5 * 5 * depth2\n",
    "        # conv3 layer 3\n",
    "        pool3 = tf.nn.relu(conv2d(pool2, layer3_weights) + layer3_biases) # 1 * 1 * depth3\n",
    "#         pool3 = max_pooling(hidden3) # 1 * 1 * depth3\n",
    "        \n",
    "        shape = pool3.get_shape().as_list()\n",
    "        pool3_flat = tf.reshape(pool3, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "        \n",
    "        hidden4_drop = tf.nn.dropout(pool3_flat, 0.9375)\n",
    "\n",
    "        logits_1 = tf.matmul(hidden4_drop, s1_w) + s1_b\n",
    "        logits_2 = tf.matmul(hidden4_drop, s2_w) + s2_b\n",
    "        logits_3 = tf.matmul(hidden4_drop, s3_w) + s3_b\n",
    "        logits_4 = tf.matmul(hidden4_drop, s4_w) + s4_b\n",
    "        logits_5 = tf.matmul(hidden4_drop, s5_w) + s5_b\n",
    "        \n",
    "        return [logits_1, logits_2, logits_3, logits_4, logits_5]\n",
    "    \n",
    "# Training computation.\n",
    "    logits = model(tf_train_dataset)\n",
    "    [logits_1, logits_2, logits_3, logits_4, logits_5] = model(tf_train_dataset)\n",
    "    \n",
    "    loss_per_digit = [tf.reduce_mean(\n",
    "                        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                            logits[i],\n",
    "                            tf_train_labels[:,i+1]\n",
    "                        )) + beta_regul * tf.nn.l2_loss(sw[i])\n",
    "                       for i in range(5)]\n",
    "    \n",
    "    loss = tf.add_n(loss_per_digit)\n",
    "    \n",
    "    # Optimizer.\n",
    "    learning_rate = tf.train.exponential_decay(0.05, global_step, 1000, 0.70, staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    def prediction_softmax(dataset, shape):\n",
    "        prediction = tf.pack([\n",
    "            tf.nn.softmax(model(dataset, 1.0)[0]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[1]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[2]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[3]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[4])])\n",
    "        return prediction\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = prediction_softmax(tf_train_dataset, 1.0)\n",
    "    valid_prediction = prediction_softmax(tf_valid_dataset, 1.0)             \n",
    "    test_prediction = prediction_softmax(tf_test_dataset, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 16.209852\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 500: 5.981581\n",
      "Minibatch accuracy: 1.6%\n",
      "Validation accuracy: 3.3%\n",
      "Minibatch loss at step 1000: 5.648309\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 4.0%\n",
      "Minibatch loss at step 1500: 4.760007\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 8.3%\n",
      "Minibatch loss at step 2000: 4.746642\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 12.1%\n",
      "Minibatch loss at step 2500: 4.075912\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 13.9%\n",
      "Minibatch loss at step 3000: 4.167899\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 14.8%\n",
      "Minibatch loss at step 3500: 4.798819\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 15.6%\n",
      "Minibatch loss at step 4000: 3.603654\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 17.2%\n",
      "Minibatch loss at step 4500: 4.381269\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 18.0%\n",
      "Minibatch loss at step 5000: 3.754035\n",
      "Minibatch accuracy: 23.4%\n",
      "Validation accuracy: 19.3%\n",
      "Minibatch loss at step 5500: 3.747772\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 18.8%\n",
      "Minibatch loss at step 6000: 4.115950\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 19.6%\n",
      "Minibatch loss at step 6500: 3.337996\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 19.8%\n",
      "Minibatch loss at step 7000: 4.712622\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 19.6%\n",
      "Minibatch loss at step 7500: 4.018486\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 8000: 4.053636\n",
      "Minibatch accuracy: 26.6%\n",
      "Validation accuracy: 20.2%\n",
      "Minibatch loss at step 8500: 4.623911\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 19.9%\n",
      "Minibatch loss at step 9000: 4.566420\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 20.3%\n",
      "Minibatch loss at step 9500: 3.844863\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 21.4%\n",
      "Minibatch loss at step 10000: 4.044575\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 20.9%\n",
      "Minibatch loss at step 10500: 5.038891\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 20.6%\n",
      "Minibatch loss at step 11000: 4.275420\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 21.1%\n",
      "Minibatch loss at step 11500: 3.244489\n",
      "Minibatch accuracy: 23.4%\n",
      "Validation accuracy: 20.2%\n",
      "Minibatch loss at step 12000: 3.750882\n",
      "Minibatch accuracy: 28.1%\n",
      "Validation accuracy: 20.5%\n",
      "Minibatch loss at step 12500: 3.607154\n",
      "Minibatch accuracy: 26.6%\n",
      "Validation accuracy: 21.1%\n",
      "Minibatch loss at step 13000: 4.073824\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 20.8%\n",
      "Minibatch loss at step 13500: 3.785114\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 21.4%\n",
      "Minibatch loss at step 14000: 4.022429\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 20.7%\n",
      "Minibatch loss at step 14500: 4.089881\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 21.0%\n",
      "Minibatch loss at step 15000: 3.778785\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 20.4%\n",
      "Minibatch loss at step 15500: 3.962036\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 20.8%\n",
      "Minibatch loss at step 16000: 4.217130\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 21.6%\n",
      "Minibatch loss at step 16500: 3.757998\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 20.6%\n",
      "Minibatch loss at step 17000: 3.238073\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 21.1%\n",
      "Minibatch loss at step 17500: 4.101058\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 21.2%\n",
      "Minibatch loss at step 18000: 4.521956\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 20.8%\n",
      "Minibatch loss at step 18500: 3.987187\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 21.0%\n",
      "Minibatch loss at step 19000: 3.944113\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 21.1%\n",
      "Minibatch loss at step 19500: 3.407408\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 20.9%\n",
      "Minibatch loss at step 20000: 3.857526\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 21.2%\n",
      "Test accuracy: 22.2%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 20001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % accuracy_multi(predictions, batch_labels))\n",
    "            print('Validation accuracy: %.1f%%' % accuracy_multi(valid_prediction.eval(), valid_labels))\n",
    "    print('Test accuracy: %.1f%%' % accuracy_multi(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conv_1 :             32 * 32 * 16  \n",
    "max pooling:         16 * 16 * 16  \n",
    "conv_2:              16* 16 * 32  \n",
    "max_pooling:         8 * 8 * 32  \n",
    "conv_3:              8 * 8 * 64\n",
    "max pooling:         4 * 4 * 64\n",
    "\n",
    "fully connect:       1024 * 1024  \n",
    "dropout              0.9375  \n",
    "sw_1:                1024 * 11  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5 # conv kernel size\n",
    "depth1 = 16\n",
    "depth2 = 32\n",
    "depth3 = 64\n",
    "num_hidden = 1024\n",
    "\n",
    "image_size = 32\n",
    "num_labels = 11 \n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    def get_weight_variable(name, shape):\n",
    "        return tf.get_variable(name, shape=shape, initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(1.0, shape = shape)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def conv2d(data, weight):\n",
    "        # strides [1, x_movement, y_movement, 1]\n",
    "        return tf.nn.conv2d(data, weight, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "\n",
    "    def max_pooling(data):\n",
    "        return tf.nn.max_pool(data, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    \n",
    "    def get_label_wb(weight_name):\n",
    "        weights = tf.get_variable(weight_name, shape=[num_hidden, num_labels],\\\n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "        return weights, biases \n",
    "    \n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 6))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    \n",
    "    # Varibles\n",
    "    # conv1 layer 1\n",
    "    layer1_weights = get_weight_variable('CNN_W1', [patch_size, patch_size, num_channels, depth1])\n",
    "    layer1_biases = bias_variable([depth1]) # 16\n",
    "    # conv2 layer 2\n",
    "    layer2_weights = get_weight_variable('CNN_W2', [patch_size, patch_size, depth1, depth2])\n",
    "    layer2_biases = bias_variable([depth2]) # 32\n",
    "    # conv3 layer 3\n",
    "    layer3_weights = get_weight_variable('CNN_W3', [patch_size, patch_size, depth2, depth3])\n",
    "    layer3_biases = bias_variable([depth3]) # 64\n",
    "    \n",
    "    # func1 layer 4\n",
    "    layer4_weights = get_weight_variable('FC_W1',[image_size // 8 * image_size // 8 * depth3, num_hidden])\n",
    "    layer4_biases = bias_varible([num_hidden])\n",
    "    \n",
    "    # locally connected layers\n",
    "    s1_w, s1_b = get_label_wb('S1_W')\n",
    "    s2_w, s2_b = get_label_wb('S2_W')\n",
    "    s3_w, s3_b = get_label_wb('S3_W')\n",
    "    s4_w, s4_b = get_label_wb('S4_W')\n",
    "    s5_w, s5_b = get_label_wb('S5_W')\n",
    "    \n",
    "    sw = [s1_w, s2_w, s3_w, s4_w, s5_w]\n",
    "    \n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    \n",
    "    def model(dataset, keep_prob):\n",
    "        # conv1 layer 1\n",
    "        hidden1 = tf.nn.relu(conv2d(dataset, layer1_weights) + layer1_biases) # 32 * 32 * depth1\n",
    "        pool1 = max_pooling(hidden1) # 16 * 16 * depth1\n",
    "        # conv2 layer 2\n",
    "        hidden2 = tf.nn.relu(conv2d(pool1, layer2_weights) + layer2_biases) # 16 * 16 * depth2\n",
    "        pool2 = max_pooling(hidden2) # 8 * 8 * depth2\n",
    "        # conv3 layer 3\n",
    "        hidden3 = tf.nn.relu(conv2d(pool2, layer3_weights) + layer3_biases) # 8 * 8 * depth3\n",
    "        pool3 = max_pooling(hidden3) # 4 * 4 * depth3\n",
    "        \n",
    "        shape = pool3.get_shape().as_list()\n",
    "        pool3_flat = tf.reshape(pool3, [shape[0], shape[1] * shape[2] * shape[3]]) # 1024\n",
    "        \n",
    "        # func1 layer 4\n",
    "        hidden4 = tf.nn.relu(tf.matmul(pool3_flat, layer4_weights) + layer4_biases)\n",
    "        hidden4_drop = tf.nn.dropout(hidden4, keep_prob)\n",
    "\n",
    "        logits_1 = tf.matmul(hidden4_drop, s1_w) + s1_b\n",
    "        logits_2 = tf.matmul(hidden4_drop, s2_w) + s2_b\n",
    "        logits_3 = tf.matmul(hidden4_drop, s3_w) + s3_b\n",
    "        logits_4 = tf.matmul(hidden4_drop, s4_w) + s4_b\n",
    "        logits_5 = tf.matmul(hidden4_drop, s5_w) + s5_b\n",
    "        \n",
    "        return [logits_1, logits_2, logits_3, logits_4, logits_5]\n",
    "    \n",
    "# Training computation.\n",
    "    logits = model(tf_train_dataset, 0.9375)\n",
    "    \n",
    "    loss_per_digit = [tf.reduce_mean(\n",
    "                        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                            logits[i],\n",
    "                            tf_train_labels[:,i+1]\n",
    "                        )) + beta_regul * tf.nn.l2_loss(sw[i])\n",
    "                       for i in range(5)]\n",
    "    \n",
    "    loss = tf.add_n(loss_per_digit)\n",
    "\n",
    "\n",
    "    # Optimizer.\n",
    "    learning_rate = tf.train.exponential_decay(0.001, global_step, 1000, 0.90, staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    def prediction_softmax(dataset, shape):\n",
    "        prediction = tf.pack([\n",
    "            tf.nn.softmax(model(dataset, 1.0)[0]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[1]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[2]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[3]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[4])])\n",
    "        return prediction\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = prediction_softmax(tf_train_dataset, 1.0)\n",
    "    valid_prediction = prediction_softmax(tf_valid_dataset, 1.0)             \n",
    "    test_prediction = prediction_softmax(tf_test_dataset, 1.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 19.218676\n",
      "Minibatch single digit accuracy: 5.4%\n",
      "Minibatch image accuracy: 0.0%\n",
      "Validation single digit accuracy: 18.3%\n",
      "Validation image accuracy: 1.3%\n",
      "Minibatch loss at step 500: 4.821128\n",
      "Minibatch single digit accuracy: 32.4%\n",
      "Minibatch image accuracy: 12.5%\n",
      "Validation single digit accuracy: 37.5%\n",
      "Validation image accuracy: 16.7%\n",
      "Minibatch loss at step 1000: 2.653456\n",
      "Minibatch single digit accuracy: 60.8%\n",
      "Minibatch image accuracy: 46.9%\n",
      "Validation single digit accuracy: 65.2%\n",
      "Validation image accuracy: 49.5%\n",
      "Minibatch loss at step 1500: 1.684686\n",
      "Minibatch single digit accuracy: 80.0%\n",
      "Minibatch image accuracy: 70.3%\n",
      "Validation single digit accuracy: 73.1%\n",
      "Validation image accuracy: 58.9%\n",
      "Minibatch loss at step 2000: 1.625933\n",
      "Minibatch single digit accuracy: 77.5%\n",
      "Minibatch image accuracy: 64.1%\n",
      "Validation single digit accuracy: 75.5%\n",
      "Validation image accuracy: 62.5%\n",
      "Minibatch loss at step 2500: 0.746641\n",
      "Minibatch single digit accuracy: 91.2%\n",
      "Minibatch image accuracy: 81.2%\n",
      "Validation single digit accuracy: 75.9%\n",
      "Validation image accuracy: 62.8%\n",
      "Minibatch loss at step 3000: 0.930193\n",
      "Minibatch single digit accuracy: 93.5%\n",
      "Minibatch image accuracy: 87.5%\n",
      "Validation single digit accuracy: 77.1%\n",
      "Validation image accuracy: 62.7%\n",
      "Minibatch loss at step 3500: 0.807635\n",
      "Minibatch single digit accuracy: 90.4%\n",
      "Minibatch image accuracy: 79.7%\n",
      "Validation single digit accuracy: 76.3%\n",
      "Validation image accuracy: 62.0%\n",
      "Minibatch loss at step 4000: 0.282140\n",
      "Minibatch single digit accuracy: 99.2%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 76.8%\n",
      "Validation image accuracy: 64.2%\n",
      "Minibatch loss at step 4500: 0.557138\n",
      "Minibatch single digit accuracy: 95.7%\n",
      "Minibatch image accuracy: 93.8%\n",
      "Validation single digit accuracy: 75.8%\n",
      "Validation image accuracy: 61.9%\n",
      "Minibatch loss at step 5000: 0.458212\n",
      "Minibatch single digit accuracy: 94.3%\n",
      "Minibatch image accuracy: 89.1%\n",
      "Validation single digit accuracy: 77.3%\n",
      "Validation image accuracy: 64.2%\n",
      "Minibatch loss at step 5500: 0.323312\n",
      "Minibatch single digit accuracy: 95.6%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 78.0%\n",
      "Validation image accuracy: 64.5%\n",
      "Minibatch loss at step 6000: 0.304077\n",
      "Minibatch single digit accuracy: 98.6%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 78.1%\n",
      "Validation image accuracy: 65.3%\n",
      "Minibatch loss at step 6500: 0.161779\n",
      "Minibatch single digit accuracy: 97.6%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 77.1%\n",
      "Validation image accuracy: 63.8%\n",
      "Minibatch loss at step 7000: 0.368362\n",
      "Minibatch single digit accuracy: 96.8%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 76.6%\n",
      "Validation image accuracy: 63.7%\n",
      "Minibatch loss at step 7500: 0.251682\n",
      "Minibatch single digit accuracy: 97.9%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 76.8%\n",
      "Validation image accuracy: 63.3%\n",
      "Minibatch loss at step 8000: 0.396552\n",
      "Minibatch single digit accuracy: 97.9%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 78.2%\n",
      "Validation image accuracy: 65.2%\n",
      "Minibatch loss at step 8500: 0.389750\n",
      "Minibatch single digit accuracy: 95.9%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 78.5%\n",
      "Validation image accuracy: 65.3%\n",
      "Minibatch loss at step 9000: 0.384582\n",
      "Minibatch single digit accuracy: 96.4%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 77.8%\n",
      "Validation image accuracy: 65.4%\n",
      "Minibatch loss at step 9500: 0.150732\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 77.9%\n",
      "Validation image accuracy: 65.0%\n",
      "Minibatch loss at step 10000: 0.193874\n",
      "Minibatch single digit accuracy: 98.5%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 78.1%\n",
      "Validation image accuracy: 64.7%\n",
      "Minibatch loss at step 10500: 0.218849\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 78.3%\n",
      "Validation image accuracy: 65.4%\n",
      "Minibatch loss at step 11000: 0.108967\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 79.2%\n",
      "Validation image accuracy: 67.3%\n",
      "Minibatch loss at step 11500: 0.173750\n",
      "Minibatch single digit accuracy: 97.7%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 78.6%\n",
      "Validation image accuracy: 65.4%\n",
      "Minibatch loss at step 12000: 0.106012\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 78.9%\n",
      "Validation image accuracy: 66.4%\n",
      "Minibatch loss at step 12500: 0.098109\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 78.1%\n",
      "Validation image accuracy: 65.6%\n",
      "Minibatch loss at step 13000: 0.418334\n",
      "Minibatch single digit accuracy: 98.6%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 77.9%\n",
      "Validation image accuracy: 65.1%\n",
      "Minibatch loss at step 13500: 0.290863\n",
      "Minibatch single digit accuracy: 98.6%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 78.0%\n",
      "Validation image accuracy: 66.2%\n",
      "Minibatch loss at step 14000: 0.146936\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 79.1%\n",
      "Validation image accuracy: 67.0%\n",
      "Minibatch loss at step 14500: 0.315580\n",
      "Minibatch single digit accuracy: 98.5%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 78.6%\n",
      "Validation image accuracy: 65.7%\n",
      "Minibatch loss at step 15000: 0.149370\n",
      "Minibatch single digit accuracy: 98.6%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 78.6%\n",
      "Validation image accuracy: 66.2%\n",
      "Minibatch loss at step 15500: 0.360492\n",
      "Minibatch single digit accuracy: 98.6%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 78.5%\n",
      "Validation image accuracy: 65.6%\n",
      "Minibatch loss at step 16000: 0.122609\n",
      "Minibatch single digit accuracy: 99.2%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 78.9%\n",
      "Validation image accuracy: 66.3%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-3761c58b0468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtf_train_dataset\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_train_labels\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_regul\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         _, l, predictions = session.run(\n\u001b[0;32m---> 13\u001b[0;31m           [optimizer, loss, train_prediction], feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Minibatch loss at step %d: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/RyanG/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 710\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    711\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/RyanG/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 908\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/RyanG/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 958\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    959\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/RyanG/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/RyanG/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    945\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    946\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_steps = 20001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch single digit accuracy: %.1f%%' % accuracy_single(predictions, batch_labels))\n",
    "            print('Minibatch image accuracy: %.1f%%' % accuracy_multi(predictions, batch_labels))\n",
    "            print('Validation single digit accuracy: %.1f%%' % accuracy_single(valid_prediction.eval(), valid_labels))\n",
    "            print('Validation image accuracy: %.1f%%' % accuracy_multi(valid_prediction.eval(), valid_labels))\n",
    "            \n",
    "    print('Test single digit accuracy: %.1f%%' % accuracy_single(test_prediction.eval(), test_labels))\n",
    "    print('Test image accuracy: %.1f%%' % accuracy_multi(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model v1 - Change Dropout"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conv_1 :             32 * 32 * 16  \n",
    "max pooling:         16 * 16 * 16  \n",
    "conv_2:              16* 16 * 32  \n",
    "max_pooling:         8 * 8 * 32  \n",
    "conv_3:              8 * 8 * 64\n",
    "max pooling:         4 * 4 * 64\n",
    "\n",
    "fully connect:       1024 * 1024  \n",
    "dropout              0.5  \n",
    "sw_1:                1024 * 11  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5 # conv kernel size\n",
    "depth1 = 16\n",
    "depth2 = 32\n",
    "depth3 = 64\n",
    "num_hidden = 1024\n",
    "\n",
    "image_size = 32\n",
    "num_labels = 11 \n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    def get_weight_variable(name, shape):\n",
    "        return tf.get_variable(name, shape=shape, initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(1.0, shape = shape)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def conv2d(data, weight):\n",
    "        # strides [1, x_movement, y_movement, 1]\n",
    "        return tf.nn.conv2d(data, weight, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "\n",
    "    def max_pooling(data):\n",
    "        return tf.nn.max_pool(data, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    \n",
    "    def get_label_wb(weight_name):\n",
    "        weights = tf.get_variable(weight_name, shape=[num_hidden, num_labels],\\\n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "        return weights, biases \n",
    "    \n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 6))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    \n",
    "    # Varibles\n",
    "    # conv1 layer 1\n",
    "    layer1_weights = get_weight_variable('CNN_W1', [patch_size, patch_size, num_channels, depth1])\n",
    "    layer1_biases = bias_variable([depth1]) # 16\n",
    "    # conv2 layer 2\n",
    "    layer2_weights = get_weight_variable('CNN_W2', [patch_size, patch_size, depth1, depth2])\n",
    "    layer2_biases = bias_variable([depth2]) # 32\n",
    "    # conv3 layer 3\n",
    "    layer3_weights = get_weight_variable('CNN_W3', [patch_size, patch_size, depth2, depth3])\n",
    "    layer3_biases = bias_variable([depth3]) # 64\n",
    "    \n",
    "    # func1 layer 4\n",
    "    layer4_weights = get_weight_variable('FC_W1',[image_size // 8 * image_size // 8 * depth3, num_hidden])\n",
    "    layer4_biases = bias_variable([num_hidden])\n",
    "    \n",
    "    # locally connected layers\n",
    "    s1_w, s1_b = get_label_wb('S1_W')\n",
    "    s2_w, s2_b = get_label_wb('S2_W')\n",
    "    s3_w, s3_b = get_label_wb('S3_W')\n",
    "    s4_w, s4_b = get_label_wb('S4_W')\n",
    "    s5_w, s5_b = get_label_wb('S5_W')\n",
    "    \n",
    "    sw = [s1_w, s2_w, s3_w, s4_w, s5_w]\n",
    "    \n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    \n",
    "    def model(dataset, keep_prob):\n",
    "        # conv1 layer 1\n",
    "        hidden1 = tf.nn.relu(conv2d(dataset, layer1_weights) + layer1_biases) # 32 * 32 * depth1\n",
    "        pool1 = max_pooling(hidden1) # 16 * 16 * depth1\n",
    "        # conv2 layer 2\n",
    "        hidden2 = tf.nn.relu(conv2d(pool1, layer2_weights) + layer2_biases) # 16 * 16 * depth2\n",
    "        pool2 = max_pooling(hidden2) # 8 * 8 * depth2\n",
    "        # conv3 layer 3\n",
    "        hidden3 = tf.nn.relu(conv2d(pool2, layer3_weights) + layer3_biases) # 8 * 8 * depth3\n",
    "        pool3 = max_pooling(hidden3) # 4 * 4 * depth3\n",
    "        \n",
    "        shape = pool3.get_shape().as_list()\n",
    "        pool3_flat = tf.reshape(pool3, [shape[0], shape[1] * shape[2] * shape[3]]) # 1024\n",
    "        \n",
    "        # func1 layer 4\n",
    "        hidden4 = tf.nn.relu(tf.matmul(pool3_flat, layer4_weights) + layer4_biases)\n",
    "        hidden4_drop = tf.nn.dropout(hidden4, keep_prob)\n",
    "\n",
    "        logits_1 = tf.matmul(hidden4_drop, s1_w) + s1_b\n",
    "        logits_2 = tf.matmul(hidden4_drop, s2_w) + s2_b\n",
    "        logits_3 = tf.matmul(hidden4_drop, s3_w) + s3_b\n",
    "        logits_4 = tf.matmul(hidden4_drop, s4_w) + s4_b\n",
    "        logits_5 = tf.matmul(hidden4_drop, s5_w) + s5_b\n",
    "        \n",
    "        return [logits_1, logits_2, logits_3, logits_4, logits_5]\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset, 0.5)\n",
    "    \n",
    "    loss_per_digit = [tf.reduce_mean(\n",
    "                        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                            logits[i],\n",
    "                            tf_train_labels[:,i+1]\n",
    "                        )) + beta_regul * tf.nn.l2_loss(sw[i])\n",
    "                       for i in range(5)]\n",
    "    \n",
    "    loss = tf.add_n(loss_per_digit)\n",
    "\n",
    "    # Optimizer.\n",
    "    learning_rate = tf.train.exponential_decay(0.001, global_step, 1000, 0.80, staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    def prediction_softmax(dataset, shape):\n",
    "        prediction = tf.pack([\n",
    "            tf.nn.softmax(model(dataset, 1.0)[0]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[1]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[2]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[3]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[4])])\n",
    "        return prediction\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = prediction_softmax(tf_train_dataset, 1.0)\n",
    "    valid_prediction = prediction_softmax(tf_valid_dataset, 1.0)             \n",
    "    test_prediction = prediction_softmax(tf_test_dataset, 1.0)\n",
    "    \n",
    "    # Save Model \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 30.106844\n",
      "Minibatch single digit accuracy: 4.1%\n",
      "Minibatch image accuracy: 0.0%\n",
      "Validation single digit accuracy: 18.3%\n",
      "Validation image accuracy: 1.3%\n",
      "Minibatch loss at step 500: 5.182123\n",
      "Minibatch single digit accuracy: 27.6%\n",
      "Minibatch image accuracy: 9.4%\n",
      "Validation single digit accuracy: 33.1%\n",
      "Validation image accuracy: 11.3%\n",
      "Minibatch loss at step 1000: 2.731842\n",
      "Minibatch single digit accuracy: 67.1%\n",
      "Minibatch image accuracy: 53.1%\n",
      "Validation single digit accuracy: 64.2%\n",
      "Validation image accuracy: 49.1%\n",
      "Minibatch loss at step 1500: 1.559345\n",
      "Minibatch single digit accuracy: 80.7%\n",
      "Minibatch image accuracy: 67.2%\n",
      "Validation single digit accuracy: 73.2%\n",
      "Validation image accuracy: 60.0%\n",
      "Minibatch loss at step 2000: 1.872497\n",
      "Minibatch single digit accuracy: 76.8%\n",
      "Minibatch image accuracy: 70.3%\n",
      "Validation single digit accuracy: 75.7%\n",
      "Validation image accuracy: 63.6%\n",
      "Minibatch loss at step 2500: 1.323040\n",
      "Minibatch single digit accuracy: 87.6%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 76.7%\n",
      "Validation image accuracy: 65.1%\n",
      "Minibatch loss at step 3000: 1.700884\n",
      "Minibatch single digit accuracy: 84.2%\n",
      "Minibatch image accuracy: 76.6%\n",
      "Validation single digit accuracy: 78.6%\n",
      "Validation image accuracy: 67.1%\n",
      "Minibatch loss at step 3500: 1.147533\n",
      "Minibatch single digit accuracy: 89.0%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 79.9%\n",
      "Validation image accuracy: 68.9%\n",
      "Minibatch loss at step 4000: 0.497219\n",
      "Minibatch single digit accuracy: 93.3%\n",
      "Minibatch image accuracy: 89.1%\n",
      "Validation single digit accuracy: 80.7%\n",
      "Validation image accuracy: 70.0%\n",
      "Minibatch loss at step 4500: 0.749898\n",
      "Minibatch single digit accuracy: 94.3%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 80.1%\n",
      "Validation image accuracy: 68.9%\n",
      "Minibatch loss at step 5000: 0.653584\n",
      "Minibatch single digit accuracy: 95.0%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 80.5%\n",
      "Validation image accuracy: 69.9%\n",
      "Minibatch loss at step 5500: 0.484961\n",
      "Minibatch single digit accuracy: 97.8%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 81.2%\n",
      "Validation image accuracy: 70.5%\n",
      "Minibatch loss at step 6000: 0.604981\n",
      "Minibatch single digit accuracy: 96.6%\n",
      "Minibatch image accuracy: 93.8%\n",
      "Validation single digit accuracy: 80.9%\n",
      "Validation image accuracy: 70.5%\n",
      "Minibatch loss at step 6500: 0.350257\n",
      "Minibatch single digit accuracy: 97.6%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 80.9%\n",
      "Validation image accuracy: 70.7%\n",
      "Minibatch loss at step 7000: 0.808345\n",
      "Minibatch single digit accuracy: 96.1%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 81.5%\n",
      "Validation image accuracy: 71.1%\n",
      "Minibatch loss at step 7500: 0.344865\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 81.9%\n",
      "Validation image accuracy: 71.3%\n",
      "Minibatch loss at step 8000: 0.215929\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 81.2%\n",
      "Validation image accuracy: 70.9%\n",
      "Minibatch loss at step 8500: 0.451732\n",
      "Minibatch single digit accuracy: 98.0%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 81.7%\n",
      "Validation image accuracy: 71.1%\n",
      "Minibatch loss at step 9000: 0.379113\n",
      "Minibatch single digit accuracy: 97.8%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 82.0%\n",
      "Validation image accuracy: 72.0%\n",
      "Minibatch loss at step 9500: 0.192198\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.0%\n",
      "Validation image accuracy: 72.1%\n",
      "Minibatch loss at step 10000: 0.291765\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.3%\n",
      "Validation image accuracy: 72.2%\n",
      "Minibatch loss at step 10500: 0.263691\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.2%\n",
      "Validation image accuracy: 71.9%\n",
      "Minibatch loss at step 11000: 0.236802\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.2%\n",
      "Validation image accuracy: 72.3%\n",
      "Minibatch loss at step 11500: 0.203675\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.3%\n",
      "Validation image accuracy: 72.0%\n",
      "Minibatch loss at step 12000: 0.151470\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.2%\n",
      "Validation image accuracy: 72.2%\n",
      "Minibatch loss at step 12500: 0.149923\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.2%\n",
      "Validation image accuracy: 72.0%\n",
      "Minibatch loss at step 13000: 0.261009\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 82.3%\n",
      "Validation image accuracy: 72.2%\n",
      "Minibatch loss at step 13500: 0.204084\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.5%\n",
      "Validation image accuracy: 72.3%\n",
      "Minibatch loss at step 14000: 0.171580\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.3%\n",
      "Validation image accuracy: 72.2%\n",
      "Minibatch loss at step 14500: 0.146198\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.4%\n",
      "Validation image accuracy: 72.4%\n",
      "Minibatch loss at step 15000: 0.156922\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.5%\n",
      "Validation image accuracy: 72.6%\n",
      "Test single digit accuracy: 81.3%\n",
      "Test image accuracy: 71.5%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 15001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch single digit accuracy: %.1f%%' % accuracy_single(predictions, batch_labels))\n",
    "            print('Minibatch image accuracy: %.1f%%' % accuracy_multi(predictions, batch_labels))\n",
    "            print('Validation single digit accuracy: %.1f%%' % accuracy_single(valid_prediction.eval(), valid_labels))\n",
    "            print('Validation image accuracy: %.1f%%' % accuracy_multi(valid_prediction.eval(), valid_labels))\n",
    "            \n",
    "    print('Test single digit accuracy: %.1f%%' % accuracy_single(test_prediction.eval(), test_labels))\n",
    "    print('Test image accuracy: %.1f%%' % accuracy_multi(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model v2 -  LRN - Local Response Normalization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conv_1 :             32 * 32 * 16  \n",
    "lrn                  32 * 32 * 16\n",
    "max pooling:         16 * 16 * 16 \n",
    "\n",
    "conv_2:              16* 16 * 32 \n",
    "lrn                  16* 16 * 32\n",
    "max_pooling:         8 * 8 * 32  \n",
    "\n",
    "conv_3:              8 * 8 * 64\n",
    "lrn                  8 * 8 * 64\n",
    "max pooling:         4 * 4 * 64\n",
    "\n",
    "fully connect:       1024 * 1024  \n",
    "dropout              0.5  \n",
    "sw_1:                1024 * 11  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5 # conv kernel size\n",
    "depth1 = 16\n",
    "depth2 = 32\n",
    "depth3 = 64\n",
    "num_hidden = 1024\n",
    "\n",
    "image_size = 32\n",
    "num_labels = 11 \n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    def get_weight_variable(name, shape):\n",
    "        return tf.get_variable(name, shape=shape, initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(1.0, shape = shape)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def conv2d(data, weight):\n",
    "        # strides [1, x_movement, y_movement, 1]\n",
    "        return tf.nn.conv2d(data, weight, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "\n",
    "    def max_pooling(data):\n",
    "        return tf.nn.max_pool(data, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    \n",
    "    def get_label_wb(weight_name):\n",
    "        weights = tf.get_variable(weight_name, shape=[num_hidden, num_labels],\\\n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "        return weights, biases \n",
    "    \n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 6))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    \n",
    "    # Varibles\n",
    "    # conv1 layer 1\n",
    "    layer1_weights = get_weight_variable('CNN_W1', [patch_size, patch_size, num_channels, depth1])\n",
    "    layer1_biases = bias_variable([depth1]) # 16\n",
    "    # conv2 layer 2\n",
    "    layer2_weights = get_weight_variable('CNN_W2', [patch_size, patch_size, depth1, depth2])\n",
    "    layer2_biases = bias_variable([depth2]) # 32\n",
    "    # conv3 layer 3\n",
    "    layer3_weights = get_weight_variable('CNN_W3', [patch_size, patch_size, depth2, depth3])\n",
    "    layer3_biases = bias_variable([depth3]) # 64\n",
    "    \n",
    "    # func1 layer 4\n",
    "    layer4_weights = get_weight_variable('FC_W1',[image_size // 8 * image_size // 8 * depth3, num_hidden])\n",
    "    layer4_biases = bias_variable([num_hidden])\n",
    "    \n",
    "    # locally connected layers\n",
    "    s1_w, s1_b = get_label_wb('S1_W')\n",
    "    s2_w, s2_b = get_label_wb('S2_W')\n",
    "    s3_w, s3_b = get_label_wb('S3_W')\n",
    "    s4_w, s4_b = get_label_wb('S4_W')\n",
    "    s5_w, s5_b = get_label_wb('S5_W')\n",
    "    \n",
    "    sw = [s1_w, s2_w, s3_w, s4_w, s5_w]\n",
    "    \n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    \n",
    "    def model(dataset, keep_prob):\n",
    "        # conv1 layer 1\n",
    "        hidden1 = tf.nn.relu(conv2d(dataset, layer1_weights) + layer1_biases) # 32 * 32 * depth1\n",
    "        hidden1 = tf.nn.local_response_normalization(hidden1)\n",
    "        pool1 = max_pooling(hidden1) # 16 * 16 * depth1\n",
    "        # conv2 layer 2\n",
    "        hidden2 = tf.nn.relu(conv2d(pool1, layer2_weights) + layer2_biases) # 16 * 16 * depth2\n",
    "        hidden2 = tf.nn.local_response_normalization(hidden2)\n",
    "        pool2 = max_pooling(hidden2) # 8 * 8 * depth2\n",
    "        # conv3 layer 3\n",
    "        hidden3 = tf.nn.relu(conv2d(pool2, layer3_weights) + layer3_biases) # 8 * 8 * depth3\n",
    "        hidden3 = tf.nn.local_response_normalization(hidden3)\n",
    "        pool3 = max_pooling(hidden3) # 4 * 4 * depth3\n",
    "        \n",
    "        shape = pool3.get_shape().as_list()\n",
    "        pool3_flat = tf.reshape(pool3, [shape[0], shape[1] * shape[2] * shape[3]]) # 1024\n",
    "        \n",
    "        # func1 layer 4\n",
    "        hidden4 = tf.nn.relu(tf.matmul(pool3_flat, layer4_weights) + layer4_biases)\n",
    "        hidden4_drop = tf.nn.dropout(hidden4, keep_prob)\n",
    "\n",
    "        logits_1 = tf.matmul(hidden4_drop, s1_w) + s1_b\n",
    "        logits_2 = tf.matmul(hidden4_drop, s2_w) + s2_b\n",
    "        logits_3 = tf.matmul(hidden4_drop, s3_w) + s3_b\n",
    "        logits_4 = tf.matmul(hidden4_drop, s4_w) + s4_b\n",
    "        logits_5 = tf.matmul(hidden4_drop, s5_w) + s5_b\n",
    "        \n",
    "        return [logits_1, logits_2, logits_3, logits_4, logits_5]\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset, 0.5)\n",
    "    \n",
    "    loss_per_digit = [tf.reduce_mean(\n",
    "                        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                            logits[i],\n",
    "                            tf_train_labels[:,i+1]\n",
    "                        )) + beta_regul * tf.nn.l2_loss(sw[i])\n",
    "                       for i in range(5)]\n",
    "    \n",
    "    loss = tf.add_n(loss_per_digit)\n",
    "\n",
    "    # Optimizer.\n",
    "    learning_rate = tf.train.exponential_decay(0.001, global_step, 1000, 0.80, staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    def prediction_softmax(dataset, shape):\n",
    "        prediction = tf.pack([\n",
    "            tf.nn.softmax(model(dataset, 1.0)[0]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[1]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[2]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[3]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[4])])\n",
    "        return prediction\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = prediction_softmax(tf_train_dataset, 1.0)\n",
    "    valid_prediction = prediction_softmax(tf_valid_dataset, 1.0)             \n",
    "    test_prediction = prediction_softmax(tf_test_dataset, 1.0)\n",
    "    \n",
    "    # Save Model \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 13.347601\n",
      "Minibatch single digit accuracy: 9.5%\n",
      "Minibatch image accuracy: 0.0%\n",
      "Validation single digit accuracy: 19.5%\n",
      "Validation image accuracy: 3.6%\n",
      "Minibatch loss at step 500: 5.714209\n",
      "Minibatch single digit accuracy: 16.6%\n",
      "Minibatch image accuracy: 3.1%\n",
      "Validation single digit accuracy: 20.8%\n",
      "Validation image accuracy: 3.7%\n",
      "Minibatch loss at step 1000: 3.024511\n",
      "Minibatch single digit accuracy: 60.8%\n",
      "Minibatch image accuracy: 45.3%\n",
      "Validation single digit accuracy: 59.9%\n",
      "Validation image accuracy: 42.4%\n",
      "Minibatch loss at step 1500: 1.887626\n",
      "Minibatch single digit accuracy: 79.3%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 71.9%\n",
      "Validation image accuracy: 58.0%\n",
      "Minibatch loss at step 2000: 2.053926\n",
      "Minibatch single digit accuracy: 78.2%\n",
      "Minibatch image accuracy: 65.6%\n",
      "Validation single digit accuracy: 76.5%\n",
      "Validation image accuracy: 63.9%\n",
      "Minibatch loss at step 2500: 1.215583\n",
      "Minibatch single digit accuracy: 87.6%\n",
      "Minibatch image accuracy: 76.6%\n",
      "Validation single digit accuracy: 77.0%\n",
      "Validation image accuracy: 65.2%\n",
      "Minibatch loss at step 3000: 1.490098\n",
      "Minibatch single digit accuracy: 80.6%\n",
      "Minibatch image accuracy: 67.2%\n",
      "Validation single digit accuracy: 79.0%\n",
      "Validation image accuracy: 67.7%\n",
      "Minibatch loss at step 3500: 1.245708\n",
      "Minibatch single digit accuracy: 88.4%\n",
      "Minibatch image accuracy: 76.6%\n",
      "Validation single digit accuracy: 80.1%\n",
      "Validation image accuracy: 69.1%\n",
      "Minibatch loss at step 4000: 0.485543\n",
      "Minibatch single digit accuracy: 95.8%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 80.3%\n",
      "Validation image accuracy: 69.2%\n",
      "Minibatch loss at step 4500: 0.783474\n",
      "Minibatch single digit accuracy: 92.9%\n",
      "Minibatch image accuracy: 89.1%\n",
      "Validation single digit accuracy: 81.8%\n",
      "Validation image accuracy: 70.8%\n",
      "Minibatch loss at step 5000: 0.794374\n",
      "Minibatch single digit accuracy: 93.6%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 81.3%\n",
      "Validation image accuracy: 70.3%\n",
      "Minibatch loss at step 5500: 0.502143\n",
      "Minibatch single digit accuracy: 96.3%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 81.5%\n",
      "Validation image accuracy: 70.5%\n",
      "Minibatch loss at step 6000: 0.623720\n",
      "Minibatch single digit accuracy: 93.8%\n",
      "Minibatch image accuracy: 87.5%\n",
      "Validation single digit accuracy: 82.0%\n",
      "Validation image accuracy: 71.8%\n",
      "Minibatch loss at step 6500: 0.379734\n",
      "Minibatch single digit accuracy: 98.4%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 82.3%\n",
      "Validation image accuracy: 71.7%\n",
      "Minibatch loss at step 7000: 0.985863\n",
      "Minibatch single digit accuracy: 92.9%\n",
      "Minibatch image accuracy: 85.9%\n",
      "Validation single digit accuracy: 82.2%\n",
      "Validation image accuracy: 71.3%\n",
      "Minibatch loss at step 7500: 0.647111\n",
      "Minibatch single digit accuracy: 97.9%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 82.7%\n",
      "Validation image accuracy: 72.0%\n",
      "Minibatch loss at step 8000: 0.349782\n",
      "Minibatch single digit accuracy: 98.6%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 82.4%\n",
      "Validation image accuracy: 71.6%\n",
      "Minibatch loss at step 8500: 0.779169\n",
      "Minibatch single digit accuracy: 94.6%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 82.6%\n",
      "Validation image accuracy: 71.5%\n",
      "Minibatch loss at step 9000: 0.671618\n",
      "Minibatch single digit accuracy: 96.4%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 82.8%\n",
      "Validation image accuracy: 72.7%\n",
      "Minibatch loss at step 9500: 0.327232\n",
      "Minibatch single digit accuracy: 97.8%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 82.8%\n",
      "Validation image accuracy: 72.3%\n",
      "Minibatch loss at step 10000: 0.569709\n",
      "Minibatch single digit accuracy: 98.5%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 83.1%\n",
      "Validation image accuracy: 72.3%\n",
      "Minibatch loss at step 10500: 0.703843\n",
      "Minibatch single digit accuracy: 96.7%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 82.8%\n",
      "Validation image accuracy: 72.1%\n",
      "Minibatch loss at step 11000: 0.519143\n",
      "Minibatch single digit accuracy: 97.9%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 82.6%\n",
      "Validation image accuracy: 72.0%\n",
      "Minibatch loss at step 11500: 0.376376\n",
      "Minibatch single digit accuracy: 98.5%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 83.2%\n",
      "Validation image accuracy: 72.8%\n",
      "Minibatch loss at step 12000: 0.454119\n",
      "Minibatch single digit accuracy: 97.8%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 83.2%\n",
      "Validation image accuracy: 73.1%\n",
      "Minibatch loss at step 12500: 0.415269\n",
      "Minibatch single digit accuracy: 97.8%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 83.1%\n",
      "Validation image accuracy: 72.8%\n",
      "Minibatch loss at step 13000: 0.526294\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 83.4%\n",
      "Validation image accuracy: 73.0%\n",
      "Minibatch loss at step 13500: 0.407928\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 83.0%\n",
      "Validation image accuracy: 72.6%\n",
      "Minibatch loss at step 14000: 0.395952\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 83.0%\n",
      "Validation image accuracy: 72.3%\n",
      "Minibatch loss at step 14500: 0.292382\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 83.3%\n",
      "Validation image accuracy: 73.1%\n",
      "Minibatch loss at step 15000: 0.341074\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 83.3%\n",
      "Validation image accuracy: 73.1%\n",
      "Test single digit accuracy: 82.2%\n",
      "Test image accuracy: 72.2%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 15001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch single digit accuracy: %.1f%%' % accuracy_single(predictions, batch_labels))\n",
    "            print('Minibatch image accuracy: %.1f%%' % accuracy_multi(predictions, batch_labels))\n",
    "            print('Validation single digit accuracy: %.1f%%' % accuracy_single(valid_prediction.eval(), valid_labels))\n",
    "            print('Validation image accuracy: %.1f%%' % accuracy_multi(valid_prediction.eval(), valid_labels))\n",
    "            \n",
    "    print('Test single digit accuracy: %.1f%%' % accuracy_single(test_prediction.eval(), test_labels))\n",
    "    print('Test image accuracy: %.1f%%' % accuracy_multi(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model v3 - add dropout to all hidden layers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conv_1 :             32 * 32 * 16  \n",
    "lrn                  32 * 32 * 16\n",
    "max pooling:         16 * 16 * 16 \n",
    "\n",
    "conv_2:              16 * 16 * 32 \n",
    "lrn                  16 * 16 * 32\n",
    "max_pooling:         8 * 8 * 32  \n",
    "dropout              0.8\n",
    "\n",
    "conv_3:              8 * 8 * 64\n",
    "lrn                  8 * 8 * 64\n",
    "max pooling:         4 * 4 * 64\n",
    "dropout              0.8\n",
    "\n",
    "fully connect:       1024 * 1024  \n",
    "dropout              0.5  \n",
    "sw_1:                1024 * 11  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5 # conv kernel size\n",
    "depth1 = 16\n",
    "depth2 = 32\n",
    "depth3 = 64\n",
    "num_hidden = 1024\n",
    "\n",
    "image_size = 32\n",
    "num_labels = 11 \n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    def get_weight_variable(name, shape):\n",
    "        return tf.get_variable(name, shape=shape, initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(1.0, shape = shape)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def conv2d(data, weight):\n",
    "        # strides [1, x_movement, y_movement, 1]\n",
    "        return tf.nn.conv2d(data, weight, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "\n",
    "    def max_pooling(data):\n",
    "        return tf.nn.max_pool(data, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    \n",
    "    def get_label_wb(weight_name):\n",
    "        weights = tf.get_variable(weight_name, shape=[num_hidden, num_labels],\\\n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "        return weights, biases \n",
    "    \n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 6))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    \n",
    "    # Varibles\n",
    "    # conv1 layer 1\n",
    "    layer1_weights = get_weight_variable('CNN_W1', [patch_size, patch_size, num_channels, depth1])\n",
    "    layer1_biases = bias_variable([depth1]) # 16\n",
    "    # conv2 layer 2\n",
    "    layer2_weights = get_weight_variable('CNN_W2', [patch_size, patch_size, depth1, depth2])\n",
    "    layer2_biases = bias_variable([depth2]) # 32\n",
    "    # conv3 layer 3\n",
    "    layer3_weights = get_weight_variable('CNN_W3', [patch_size, patch_size, depth2, depth3])\n",
    "    layer3_biases = bias_variable([depth3]) # 64\n",
    "    \n",
    "    # func1 layer 4\n",
    "    layer4_weights = get_weight_variable('FC_W1',[4 * 4 * depth3, num_hidden])\n",
    "    layer4_biases = bias_variable([num_hidden])\n",
    "    \n",
    "    # locally connected layers\n",
    "    s1_w, s1_b = get_label_wb('S1_W')\n",
    "    s2_w, s2_b = get_label_wb('S2_W')\n",
    "    s3_w, s3_b = get_label_wb('S3_W')\n",
    "    s4_w, s4_b = get_label_wb('S4_W')\n",
    "    s5_w, s5_b = get_label_wb('S5_W')\n",
    "    \n",
    "    sw = [s1_w, s2_w, s3_w, s4_w, s5_w]\n",
    "    \n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    \n",
    "    def model(dataset, keep_prob, keep_prob2):\n",
    "        # conv1 layer 1\n",
    "        hidden1 = tf.nn.relu(conv2d(dataset, layer1_weights) + layer1_biases) # 32 * 32 * depth1\n",
    "        hidden1 = tf.nn.local_response_normalization(hidden1)\n",
    "        pool1 = max_pooling(hidden1) # 16 * 16 * depth1\n",
    "        \n",
    "        # conv2 layer 2\n",
    "        hidden2 = tf.nn.relu(conv2d(pool1, layer2_weights) + layer2_biases) # 16 * 16 * depth2\n",
    "        hidden2 = tf.nn.local_response_normalization(hidden2)\n",
    "        pool2 = max_pooling(hidden2) # 8 * 8 * depth2\n",
    "        \n",
    "        pool2 = tf.nn.dropout(pool2, keep_prob2)\n",
    "        \n",
    "        # conv3 layer 3\n",
    "        hidden3 = tf.nn.relu(conv2d(pool2, layer3_weights) + layer3_biases) # 8 * 8 * depth3\n",
    "        hidden3 = tf.nn.local_response_normalization(hidden3)\n",
    "        pool3 = max_pooling(hidden3) # 4 * 4 * depth3\n",
    "        \n",
    "        pool3 = tf.nn.dropout(pool3, keep_prob2)\n",
    "        \n",
    "        shape = pool3.get_shape().as_list()\n",
    "        pool3_flat = tf.reshape(pool3, [shape[0], shape[1] * shape[2] * shape[3]]) # 1024\n",
    "        \n",
    "        # func1 layer 4\n",
    "        hidden4 = tf.nn.relu(tf.matmul(pool3_flat, layer4_weights) + layer4_biases)\n",
    "        hidden4_drop = tf.nn.dropout(hidden4, keep_prob)\n",
    "\n",
    "        logits_1 = tf.matmul(hidden4_drop, s1_w) + s1_b\n",
    "        logits_2 = tf.matmul(hidden4_drop, s2_w) + s2_b\n",
    "        logits_3 = tf.matmul(hidden4_drop, s3_w) + s3_b\n",
    "        logits_4 = tf.matmul(hidden4_drop, s4_w) + s4_b\n",
    "        logits_5 = tf.matmul(hidden4_drop, s5_w) + s5_b\n",
    "        \n",
    "        return [logits_1, logits_2, logits_3, logits_4, logits_5]\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset, 0.5, 0.8)\n",
    "    \n",
    "    loss_per_digit = [tf.reduce_mean(\n",
    "                        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                            logits[i],\n",
    "                            tf_train_labels[:,i+1]\n",
    "                        )) + beta_regul * tf.nn.l2_loss(sw[i])\n",
    "                       for i in range(5)]\n",
    "    \n",
    "    loss = tf.add_n(loss_per_digit)\n",
    "\n",
    "    # Optimizer.\n",
    "    learning_rate = tf.train.exponential_decay(0.001, global_step, 1000, 0.90, staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    def prediction_softmax(dataset):\n",
    "        prediction = tf.pack([\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[0]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[1]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[2]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[3]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[4])])\n",
    "        return prediction\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = prediction_softmax(tf_train_dataset)\n",
    "    valid_prediction = prediction_softmax(tf_valid_dataset)             \n",
    "    test_prediction = prediction_softmax(tf_test_dataset)\n",
    "    \n",
    "    # Save Model \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 26.544254\n",
      "Minibatch single digit accuracy: 9.5%\n",
      "Minibatch image accuracy: 0.0%\n",
      "Validation single digit accuracy: 18.0%\n",
      "Validation image accuracy: 1.2%\n",
      "Minibatch loss at step 500: 6.082138\n",
      "Minibatch single digit accuracy: 15.2%\n",
      "Minibatch image accuracy: 3.1%\n",
      "Validation single digit accuracy: 19.5%\n",
      "Validation image accuracy: 3.6%\n",
      "Minibatch loss at step 1000: 4.306312\n",
      "Minibatch single digit accuracy: 39.9%\n",
      "Minibatch image accuracy: 18.8%\n",
      "Validation single digit accuracy: 40.4%\n",
      "Validation image accuracy: 18.9%\n",
      "Minibatch loss at step 1500: 2.673647\n",
      "Minibatch single digit accuracy: 67.9%\n",
      "Minibatch image accuracy: 51.6%\n",
      "Validation single digit accuracy: 64.2%\n",
      "Validation image accuracy: 47.0%\n",
      "Minibatch loss at step 2000: 2.611204\n",
      "Minibatch single digit accuracy: 71.8%\n",
      "Minibatch image accuracy: 56.2%\n",
      "Validation single digit accuracy: 73.3%\n",
      "Validation image accuracy: 59.7%\n",
      "Minibatch loss at step 2500: 1.609107\n",
      "Minibatch single digit accuracy: 85.4%\n",
      "Minibatch image accuracy: 75.0%\n",
      "Validation single digit accuracy: 76.3%\n",
      "Validation image accuracy: 63.9%\n",
      "Minibatch loss at step 3000: 1.835800\n",
      "Minibatch single digit accuracy: 77.0%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 77.9%\n",
      "Validation image accuracy: 66.2%\n",
      "Minibatch loss at step 3500: 1.839083\n",
      "Minibatch single digit accuracy: 82.9%\n",
      "Minibatch image accuracy: 71.9%\n",
      "Validation single digit accuracy: 79.3%\n",
      "Validation image accuracy: 68.3%\n",
      "Minibatch loss at step 4000: 1.030183\n",
      "Minibatch single digit accuracy: 91.6%\n",
      "Minibatch image accuracy: 89.1%\n",
      "Validation single digit accuracy: 80.0%\n",
      "Validation image accuracy: 69.7%\n",
      "Minibatch loss at step 4500: 1.287851\n",
      "Minibatch single digit accuracy: 90.0%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 81.0%\n",
      "Validation image accuracy: 70.1%\n",
      "Minibatch loss at step 5000: 1.175619\n",
      "Minibatch single digit accuracy: 86.4%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 81.8%\n",
      "Validation image accuracy: 71.2%\n",
      "Minibatch loss at step 5500: 0.985387\n",
      "Minibatch single digit accuracy: 91.9%\n",
      "Minibatch image accuracy: 85.9%\n",
      "Validation single digit accuracy: 82.3%\n",
      "Validation image accuracy: 71.7%\n",
      "Minibatch loss at step 6000: 1.259826\n",
      "Minibatch single digit accuracy: 90.3%\n",
      "Minibatch image accuracy: 84.4%\n",
      "Validation single digit accuracy: 82.6%\n",
      "Validation image accuracy: 72.3%\n",
      "Minibatch loss at step 6500: 0.960211\n",
      "Minibatch single digit accuracy: 93.5%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 82.8%\n",
      "Validation image accuracy: 73.0%\n",
      "Minibatch loss at step 7000: 1.526399\n",
      "Minibatch single digit accuracy: 83.1%\n",
      "Minibatch image accuracy: 70.3%\n",
      "Validation single digit accuracy: 83.7%\n",
      "Validation image accuracy: 74.0%\n",
      "Minibatch loss at step 7500: 0.959631\n",
      "Minibatch single digit accuracy: 92.3%\n",
      "Minibatch image accuracy: 84.4%\n",
      "Validation single digit accuracy: 83.5%\n",
      "Validation image accuracy: 73.8%\n",
      "Minibatch loss at step 8000: 0.926249\n",
      "Minibatch single digit accuracy: 95.1%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 84.2%\n",
      "Validation image accuracy: 74.6%\n",
      "Minibatch loss at step 8500: 1.420650\n",
      "Minibatch single digit accuracy: 87.8%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 84.1%\n",
      "Validation image accuracy: 74.4%\n",
      "Minibatch loss at step 9000: 1.501634\n",
      "Minibatch single digit accuracy: 95.0%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 84.4%\n",
      "Validation image accuracy: 74.8%\n",
      "Minibatch loss at step 9500: 0.805985\n",
      "Minibatch single digit accuracy: 94.2%\n",
      "Minibatch image accuracy: 87.5%\n",
      "Validation single digit accuracy: 84.3%\n",
      "Validation image accuracy: 74.7%\n",
      "Minibatch loss at step 10000: 0.964842\n",
      "Minibatch single digit accuracy: 96.3%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 84.6%\n",
      "Validation image accuracy: 74.8%\n",
      "Minibatch loss at step 10500: 1.436502\n",
      "Minibatch single digit accuracy: 94.8%\n",
      "Minibatch image accuracy: 89.1%\n",
      "Validation single digit accuracy: 84.2%\n",
      "Validation image accuracy: 74.9%\n",
      "Minibatch loss at step 11000: 1.181801\n",
      "Minibatch single digit accuracy: 91.5%\n",
      "Minibatch image accuracy: 81.2%\n",
      "Validation single digit accuracy: 84.6%\n",
      "Validation image accuracy: 75.6%\n",
      "Minibatch loss at step 11500: 0.569280\n",
      "Minibatch single digit accuracy: 96.2%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 84.7%\n",
      "Validation image accuracy: 75.5%\n",
      "Minibatch loss at step 12000: 0.868071\n",
      "Minibatch single digit accuracy: 95.6%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 85.0%\n",
      "Validation image accuracy: 75.6%\n",
      "Minibatch loss at step 12500: 0.646528\n",
      "Minibatch single digit accuracy: 97.1%\n",
      "Minibatch image accuracy: 93.8%\n",
      "Validation single digit accuracy: 84.8%\n",
      "Validation image accuracy: 75.5%\n",
      "Minibatch loss at step 13000: 1.315371\n",
      "Minibatch single digit accuracy: 96.5%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 84.9%\n",
      "Validation image accuracy: 75.8%\n",
      "Minibatch loss at step 13500: 0.909154\n",
      "Minibatch single digit accuracy: 95.1%\n",
      "Minibatch image accuracy: 89.1%\n",
      "Validation single digit accuracy: 85.0%\n",
      "Validation image accuracy: 75.9%\n",
      "Minibatch loss at step 14000: 1.123146\n",
      "Minibatch single digit accuracy: 96.4%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 85.3%\n",
      "Validation image accuracy: 76.2%\n",
      "Minibatch loss at step 14500: 0.805401\n",
      "Minibatch single digit accuracy: 96.3%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 85.3%\n",
      "Validation image accuracy: 76.2%\n",
      "Minibatch loss at step 15000: 0.658818\n",
      "Minibatch single digit accuracy: 98.6%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 85.5%\n",
      "Validation image accuracy: 76.3%\n",
      "Minibatch loss at step 15500: 0.753241\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 85.4%\n",
      "Validation image accuracy: 76.2%\n",
      "Minibatch loss at step 16000: 0.775419\n",
      "Minibatch single digit accuracy: 96.2%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 85.3%\n",
      "Validation image accuracy: 76.1%\n",
      "Minibatch loss at step 16500: 0.794621\n",
      "Minibatch single digit accuracy: 97.0%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 85.3%\n",
      "Validation image accuracy: 76.0%\n",
      "Minibatch loss at step 17000: 0.543207\n",
      "Minibatch single digit accuracy: 99.2%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 85.4%\n",
      "Validation image accuracy: 76.2%\n",
      "Minibatch loss at step 17500: 0.939861\n",
      "Minibatch single digit accuracy: 96.6%\n",
      "Minibatch image accuracy: 93.8%\n",
      "Validation single digit accuracy: 85.9%\n",
      "Validation image accuracy: 76.7%\n",
      "Minibatch loss at step 18000: 1.012314\n",
      "Minibatch single digit accuracy: 97.4%\n",
      "Minibatch image accuracy: 93.8%\n",
      "Validation single digit accuracy: 85.8%\n",
      "Validation image accuracy: 76.7%\n",
      "Minibatch loss at step 18500: 0.597680\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 85.4%\n",
      "Validation image accuracy: 76.2%\n",
      "Minibatch loss at step 19000: 0.569003\n",
      "Minibatch single digit accuracy: 97.7%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 85.4%\n",
      "Validation image accuracy: 76.3%\n",
      "Minibatch loss at step 19500: 0.598698\n",
      "Minibatch single digit accuracy: 97.1%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 85.9%\n",
      "Validation image accuracy: 76.8%\n",
      "Minibatch loss at step 20000: 0.691507\n",
      "Minibatch single digit accuracy: 97.7%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 85.8%\n",
      "Validation image accuracy: 76.6%\n",
      "Test single digit accuracy: 84.8%\n",
      "Test image accuracy: 75.9%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 20001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch single digit accuracy: %.1f%%' % accuracy_single(predictions, batch_labels))\n",
    "            print('Minibatch image accuracy: %.1f%%' % accuracy_multi(predictions, batch_labels))\n",
    "            print('Validation single digit accuracy: %.1f%%' % accuracy_single(valid_prediction.eval(), valid_labels))\n",
    "            print('Validation image accuracy: %.1f%%' % accuracy_multi(valid_prediction.eval(), valid_labels))\n",
    "            \n",
    "    print('Test single digit accuracy: %.1f%%' % accuracy_single(test_prediction.eval(), test_labels))\n",
    "    print('Test image accuracy: %.1f%%' % accuracy_multi(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model v4 - change dropout on cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5 # conv kernel size\n",
    "depth1 = 16\n",
    "depth2 = 32\n",
    "depth3 = 64\n",
    "num_hidden = 1024\n",
    "\n",
    "image_size = 32\n",
    "num_labels = 11 \n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    def get_weight_variable(name, shape):\n",
    "        return tf.get_variable(name, shape=shape, initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(1.0, shape = shape)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def conv2d(data, weight):\n",
    "        # strides [1, x_movement, y_movement, 1]\n",
    "        return tf.nn.conv2d(data, weight, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "\n",
    "    def max_pooling(data):\n",
    "        return tf.nn.max_pool(data, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    \n",
    "    def get_label_wb(weight_name):\n",
    "        weights = tf.get_variable(weight_name, shape=[num_hidden, num_labels],\\\n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "        return weights, biases \n",
    "    \n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 6))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    \n",
    "    # Varibles\n",
    "    # conv1 layer 1\n",
    "    layer1_weights = get_weight_variable('CNN_W1', [patch_size, patch_size, num_channels, depth1])\n",
    "    layer1_biases = bias_variable([depth1]) # 16\n",
    "    # conv2 layer 2\n",
    "    layer2_weights = get_weight_variable('CNN_W2', [patch_size, patch_size, depth1, depth2])\n",
    "    layer2_biases = bias_variable([depth2]) # 32\n",
    "    # conv3 layer 3\n",
    "    layer3_weights = get_weight_variable('CNN_W3', [patch_size, patch_size, depth2, depth3])\n",
    "    layer3_biases = bias_variable([depth3]) # 64\n",
    "    \n",
    "    # func1 layer 4\n",
    "    layer4_weights = get_weight_variable('FC_W1',[4 * 4 * depth3, num_hidden])\n",
    "    layer4_biases = bias_variable([num_hidden])\n",
    "    \n",
    "    # locally connected layers\n",
    "    s1_w, s1_b = get_label_wb('S1_W')\n",
    "    s2_w, s2_b = get_label_wb('S2_W')\n",
    "    s3_w, s3_b = get_label_wb('S3_W')\n",
    "    s4_w, s4_b = get_label_wb('S4_W')\n",
    "    s5_w, s5_b = get_label_wb('S5_W')\n",
    "    \n",
    "    sw = [s1_w, s2_w, s3_w, s4_w, s5_w]\n",
    "    \n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    \n",
    "    def model(dataset, keep_prob, keep_prob2):\n",
    "        # conv1 layer 1\n",
    "        hidden1 = tf.nn.relu(conv2d(dataset, layer1_weights) + layer1_biases) # 32 * 32 * depth1\n",
    "        hidden1 = tf.nn.local_response_normalization(hidden1)\n",
    "        pool1 = max_pooling(hidden1) # 16 * 16 * depth1\n",
    "        \n",
    "        # conv2 layer 2\n",
    "        hidden2 = tf.nn.relu(conv2d(pool1, layer2_weights) + layer2_biases) # 16 * 16 * depth2\n",
    "        hidden2 = tf.nn.local_response_normalization(hidden2)\n",
    "        pool2 = max_pooling(hidden2) # 8 * 8 * depth2\n",
    "        \n",
    "        pool2 = tf.nn.dropout(pool2, keep_prob2)\n",
    "        \n",
    "        # conv3 layer 3\n",
    "        hidden3 = tf.nn.relu(conv2d(pool2, layer3_weights) + layer3_biases) # 8 * 8 * depth3\n",
    "        hidden3 = tf.nn.local_response_normalization(hidden3)\n",
    "        pool3 = max_pooling(hidden3) # 4 * 4 * depth3\n",
    "        \n",
    "        pool3 = tf.nn.dropout(pool3, keep_prob2)\n",
    "        \n",
    "        shape = pool3.get_shape().as_list()\n",
    "        pool3_flat = tf.reshape(pool3, [shape[0], shape[1] * shape[2] * shape[3]]) # 1024\n",
    "        \n",
    "        # func1 layer 4\n",
    "        hidden4 = tf.nn.relu(tf.matmul(pool3_flat, layer4_weights) + layer4_biases)\n",
    "        hidden4_drop = tf.nn.dropout(hidden4, keep_prob)\n",
    "\n",
    "        logits_1 = tf.matmul(hidden4_drop, s1_w) + s1_b\n",
    "        logits_2 = tf.matmul(hidden4_drop, s2_w) + s2_b\n",
    "        logits_3 = tf.matmul(hidden4_drop, s3_w) + s3_b\n",
    "        logits_4 = tf.matmul(hidden4_drop, s4_w) + s4_b\n",
    "        logits_5 = tf.matmul(hidden4_drop, s5_w) + s5_b\n",
    "        \n",
    "        return [logits_1, logits_2, logits_3, logits_4, logits_5]\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset, 0.5, 0.5)\n",
    "    \n",
    "    loss_per_digit = [tf.reduce_mean(\n",
    "                        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                            logits[i],\n",
    "                            tf_train_labels[:,i+1]\n",
    "                        )) + beta_regul * tf.nn.l2_loss(sw[i])\n",
    "                       for i in range(5)]\n",
    "    \n",
    "    loss = tf.add_n(loss_per_digit)\n",
    "\n",
    "    # Optimizer.\n",
    "    learning_rate = tf.train.exponential_decay(0.001, global_step, 1000, 0.90, staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    def prediction_softmax(dataset):\n",
    "        prediction = tf.pack([\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[0]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[1]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[2]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[3]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[4])])\n",
    "        return prediction\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = prediction_softmax(tf_train_dataset)\n",
    "    valid_prediction = prediction_softmax(tf_valid_dataset)             \n",
    "    test_prediction = prediction_softmax(tf_test_dataset)\n",
    "    \n",
    "    # Save Model \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 17.567846\n",
      "Minibatch single digit accuracy: 12.2%\n",
      "Minibatch image accuracy: 0.0%\n",
      "Validation single digit accuracy: 19.5%\n",
      "Validation image accuracy: 3.6%\n",
      "Minibatch loss at step 500: 6.044502\n",
      "Minibatch single digit accuracy: 15.2%\n",
      "Minibatch image accuracy: 3.1%\n",
      "Validation single digit accuracy: 19.5%\n",
      "Validation image accuracy: 3.6%\n",
      "Minibatch loss at step 1000: 5.449240\n",
      "Minibatch single digit accuracy: 21.7%\n",
      "Minibatch image accuracy: 7.8%\n",
      "Validation single digit accuracy: 19.3%\n",
      "Validation image accuracy: 3.6%\n",
      "Minibatch loss at step 1500: 4.672151\n",
      "Minibatch single digit accuracy: 37.1%\n",
      "Minibatch image accuracy: 12.5%\n",
      "Validation single digit accuracy: 33.6%\n",
      "Validation image accuracy: 12.7%\n",
      "Minibatch loss at step 2000: 4.028084\n",
      "Minibatch single digit accuracy: 54.9%\n",
      "Minibatch image accuracy: 42.2%\n",
      "Validation single digit accuracy: 56.8%\n",
      "Validation image accuracy: 40.1%\n",
      "Minibatch loss at step 2500: 2.689013\n",
      "Minibatch single digit accuracy: 70.8%\n",
      "Minibatch image accuracy: 53.1%\n",
      "Validation single digit accuracy: 62.7%\n",
      "Validation image accuracy: 47.0%\n",
      "Minibatch loss at step 3000: 2.929991\n",
      "Minibatch single digit accuracy: 71.9%\n",
      "Minibatch image accuracy: 60.9%\n",
      "Validation single digit accuracy: 67.7%\n",
      "Validation image accuracy: 53.0%\n",
      "Minibatch loss at step 3500: 3.014989\n",
      "Minibatch single digit accuracy: 76.0%\n",
      "Minibatch image accuracy: 60.9%\n",
      "Validation single digit accuracy: 71.2%\n",
      "Validation image accuracy: 57.4%\n",
      "Minibatch loss at step 4000: 1.784424\n",
      "Minibatch single digit accuracy: 81.5%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 71.5%\n",
      "Validation image accuracy: 58.2%\n",
      "Minibatch loss at step 4500: 2.358316\n",
      "Minibatch single digit accuracy: 84.3%\n",
      "Minibatch image accuracy: 76.6%\n",
      "Validation single digit accuracy: 74.2%\n",
      "Validation image accuracy: 61.8%\n",
      "Minibatch loss at step 5000: 2.577543\n",
      "Minibatch single digit accuracy: 78.6%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 75.4%\n",
      "Validation image accuracy: 63.1%\n",
      "Minibatch loss at step 5500: 2.091293\n",
      "Minibatch single digit accuracy: 85.9%\n",
      "Minibatch image accuracy: 76.6%\n",
      "Validation single digit accuracy: 76.2%\n",
      "Validation image accuracy: 64.7%\n",
      "Minibatch loss at step 6000: 2.282319\n",
      "Minibatch single digit accuracy: 81.4%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 77.4%\n",
      "Validation image accuracy: 65.5%\n",
      "Minibatch loss at step 6500: 1.843521\n",
      "Minibatch single digit accuracy: 87.1%\n",
      "Minibatch image accuracy: 81.2%\n",
      "Validation single digit accuracy: 77.8%\n",
      "Validation image accuracy: 66.7%\n",
      "Minibatch loss at step 7000: 2.838985\n",
      "Minibatch single digit accuracy: 70.1%\n",
      "Minibatch image accuracy: 56.2%\n",
      "Validation single digit accuracy: 78.0%\n",
      "Validation image accuracy: 66.8%\n",
      "Minibatch loss at step 7500: 1.989663\n",
      "Minibatch single digit accuracy: 80.4%\n",
      "Minibatch image accuracy: 75.0%\n",
      "Validation single digit accuracy: 78.8%\n",
      "Validation image accuracy: 67.8%\n",
      "Minibatch loss at step 8000: 2.033044\n",
      "Minibatch single digit accuracy: 82.5%\n",
      "Minibatch image accuracy: 76.6%\n",
      "Validation single digit accuracy: 78.6%\n",
      "Validation image accuracy: 67.4%\n",
      "Minibatch loss at step 8500: 2.340281\n",
      "Minibatch single digit accuracy: 79.6%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 79.6%\n",
      "Validation image accuracy: 69.0%\n",
      "Minibatch loss at step 9000: 2.525029\n",
      "Minibatch single digit accuracy: 77.0%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 79.5%\n",
      "Validation image accuracy: 68.7%\n",
      "Minibatch loss at step 9500: 1.682556\n",
      "Minibatch single digit accuracy: 86.3%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 79.7%\n",
      "Validation image accuracy: 69.1%\n",
      "Minibatch loss at step 10000: 2.165486\n",
      "Minibatch single digit accuracy: 82.8%\n",
      "Minibatch image accuracy: 70.3%\n",
      "Validation single digit accuracy: 80.8%\n",
      "Validation image accuracy: 70.0%\n",
      "Minibatch loss at step 10500: 2.566441\n",
      "Minibatch single digit accuracy: 78.4%\n",
      "Minibatch image accuracy: 59.4%\n",
      "Validation single digit accuracy: 80.1%\n",
      "Validation image accuracy: 69.6%\n",
      "Minibatch loss at step 11000: 2.522482\n",
      "Minibatch single digit accuracy: 78.0%\n",
      "Minibatch image accuracy: 70.3%\n",
      "Validation single digit accuracy: 80.6%\n",
      "Validation image accuracy: 70.2%\n",
      "Minibatch loss at step 11500: 1.332847\n",
      "Minibatch single digit accuracy: 89.3%\n",
      "Minibatch image accuracy: 81.2%\n",
      "Validation single digit accuracy: 80.7%\n",
      "Validation image accuracy: 70.9%\n",
      "Minibatch loss at step 12000: 1.648906\n",
      "Minibatch single digit accuracy: 87.5%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 80.9%\n",
      "Validation image accuracy: 70.7%\n",
      "Minibatch loss at step 12500: 1.544498\n",
      "Minibatch single digit accuracy: 88.4%\n",
      "Minibatch image accuracy: 79.7%\n",
      "Validation single digit accuracy: 81.4%\n",
      "Validation image accuracy: 71.3%\n",
      "Minibatch loss at step 13000: 1.812610\n",
      "Minibatch single digit accuracy: 83.2%\n",
      "Minibatch image accuracy: 73.4%\n",
      "Validation single digit accuracy: 80.9%\n",
      "Validation image accuracy: 71.1%\n",
      "Minibatch loss at step 13500: 1.926704\n",
      "Minibatch single digit accuracy: 81.9%\n",
      "Minibatch image accuracy: 73.4%\n",
      "Validation single digit accuracy: 80.8%\n",
      "Validation image accuracy: 70.8%\n",
      "Minibatch loss at step 14000: 1.795984\n",
      "Minibatch single digit accuracy: 84.9%\n",
      "Minibatch image accuracy: 70.3%\n",
      "Validation single digit accuracy: 81.4%\n",
      "Validation image accuracy: 71.5%\n",
      "Minibatch loss at step 14500: 2.010885\n",
      "Minibatch single digit accuracy: 82.1%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 81.6%\n",
      "Validation image accuracy: 72.2%\n",
      "Minibatch loss at step 15000: 1.635014\n",
      "Minibatch single digit accuracy: 88.7%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 81.6%\n",
      "Validation image accuracy: 72.0%\n",
      "Minibatch loss at step 15500: 1.828920\n",
      "Minibatch single digit accuracy: 84.8%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 82.3%\n",
      "Validation image accuracy: 72.8%\n",
      "Minibatch loss at step 16000: 1.811475\n",
      "Minibatch single digit accuracy: 86.4%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 81.8%\n",
      "Validation image accuracy: 72.0%\n",
      "Minibatch loss at step 16500: 1.520308\n",
      "Minibatch single digit accuracy: 85.2%\n",
      "Minibatch image accuracy: 79.7%\n",
      "Validation single digit accuracy: 82.0%\n",
      "Validation image accuracy: 72.5%\n",
      "Minibatch loss at step 17000: 1.338222\n",
      "Minibatch single digit accuracy: 89.6%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 82.5%\n",
      "Validation image accuracy: 73.2%\n",
      "Minibatch loss at step 17500: 2.136766\n",
      "Minibatch single digit accuracy: 81.4%\n",
      "Minibatch image accuracy: 73.4%\n",
      "Validation single digit accuracy: 82.5%\n",
      "Validation image accuracy: 73.2%\n",
      "Minibatch loss at step 18000: 2.500756\n",
      "Minibatch single digit accuracy: 78.2%\n",
      "Minibatch image accuracy: 62.5%\n",
      "Validation single digit accuracy: 82.4%\n",
      "Validation image accuracy: 72.8%\n",
      "Minibatch loss at step 18500: 1.536660\n",
      "Minibatch single digit accuracy: 91.4%\n",
      "Minibatch image accuracy: 85.9%\n",
      "Validation single digit accuracy: 82.8%\n",
      "Validation image accuracy: 73.2%\n",
      "Minibatch loss at step 19000: 1.709830\n",
      "Minibatch single digit accuracy: 86.4%\n",
      "Minibatch image accuracy: 75.0%\n",
      "Validation single digit accuracy: 82.7%\n",
      "Validation image accuracy: 73.1%\n",
      "Minibatch loss at step 19500: 1.500337\n",
      "Minibatch single digit accuracy: 89.2%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 82.9%\n",
      "Validation image accuracy: 73.5%\n",
      "Minibatch loss at step 20000: 1.677698\n",
      "Minibatch single digit accuracy: 85.5%\n",
      "Minibatch image accuracy: 75.0%\n",
      "Validation single digit accuracy: 82.7%\n",
      "Validation image accuracy: 73.3%\n",
      "Test single digit accuracy: 82.6%\n",
      "Test image accuracy: 73.5%\n",
      "Model saved in file: 3cnn.ckpt\n"
     ]
    }
   ],
   "source": [
    "num_steps = 20001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 1e-3}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch single digit accuracy: %.1f%%' % accuracy_single(predictions, batch_labels))\n",
    "            print('Minibatch image accuracy: %.1f%%' % accuracy_multi(predictions, batch_labels))\n",
    "            print('Validation single digit accuracy: %.1f%%' % accuracy_single(valid_prediction.eval(), valid_labels))\n",
    "            print('Validation image accuracy: %.1f%%' % accuracy_multi(valid_prediction.eval(), valid_labels))\n",
    "            \n",
    "    print('Test single digit accuracy: %.1f%%' % accuracy_single(test_prediction.eval(), test_labels))\n",
    "    print('Test image accuracy: %.1f%%' % accuracy_multi(test_prediction.eval(), test_labels))\n",
    "    \n",
    "    save_path = saver.save(session, \"3cnn.ckpt\")\n",
    "    print('Model saved in file: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored!\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1.707028\n",
      "Minibatch single digit accuracy: 85.0%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 82.7%\n",
      "Validation image accuracy: 73.3%\n",
      "Minibatch loss at step 500: 1.836549\n",
      "Minibatch single digit accuracy: 85.5%\n",
      "Minibatch image accuracy: 79.7%\n",
      "Validation single digit accuracy: 83.2%\n",
      "Validation image accuracy: 73.8%\n",
      "Minibatch loss at step 1000: 1.508532\n",
      "Minibatch single digit accuracy: 86.7%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 83.1%\n",
      "Validation image accuracy: 73.8%\n",
      "Minibatch loss at step 1500: 1.532207\n",
      "Minibatch single digit accuracy: 90.0%\n",
      "Minibatch image accuracy: 85.9%\n",
      "Validation single digit accuracy: 83.0%\n",
      "Validation image accuracy: 73.7%\n",
      "Minibatch loss at step 2000: 1.768131\n",
      "Minibatch single digit accuracy: 86.6%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 83.2%\n",
      "Validation image accuracy: 74.0%\n",
      "Minibatch loss at step 2500: 1.279365\n",
      "Minibatch single digit accuracy: 93.4%\n",
      "Minibatch image accuracy: 85.9%\n",
      "Validation single digit accuracy: 83.2%\n",
      "Validation image accuracy: 73.8%\n",
      "Minibatch loss at step 3000: 1.665398\n",
      "Minibatch single digit accuracy: 84.9%\n",
      "Minibatch image accuracy: 75.0%\n",
      "Validation single digit accuracy: 83.3%\n",
      "Validation image accuracy: 74.1%\n",
      "Minibatch loss at step 3500: 1.735253\n",
      "Minibatch single digit accuracy: 87.0%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 83.4%\n",
      "Validation image accuracy: 74.0%\n",
      "Minibatch loss at step 4000: 1.263773\n",
      "Minibatch single digit accuracy: 93.3%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 83.2%\n",
      "Validation image accuracy: 74.0%\n",
      "Minibatch loss at step 4500: 1.327173\n",
      "Minibatch single digit accuracy: 92.1%\n",
      "Minibatch image accuracy: 85.9%\n",
      "Validation single digit accuracy: 83.1%\n",
      "Validation image accuracy: 73.8%\n",
      "Minibatch loss at step 5000: 1.593463\n",
      "Minibatch single digit accuracy: 90.0%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 83.6%\n",
      "Validation image accuracy: 74.4%\n",
      "Minibatch loss at step 5500: 1.241238\n",
      "Minibatch single digit accuracy: 91.9%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 83.5%\n",
      "Validation image accuracy: 74.4%\n",
      "Minibatch loss at step 6000: 1.544100\n",
      "Minibatch single digit accuracy: 85.5%\n",
      "Minibatch image accuracy: 73.4%\n",
      "Validation single digit accuracy: 83.4%\n",
      "Validation image accuracy: 74.3%\n",
      "Minibatch loss at step 6500: 1.042105\n",
      "Minibatch single digit accuracy: 91.9%\n",
      "Minibatch image accuracy: 89.1%\n",
      "Validation single digit accuracy: 83.7%\n",
      "Validation image accuracy: 74.6%\n",
      "Minibatch loss at step 7000: 2.115245\n",
      "Minibatch single digit accuracy: 81.2%\n",
      "Minibatch image accuracy: 67.2%\n",
      "Validation single digit accuracy: 83.2%\n",
      "Validation image accuracy: 74.0%\n",
      "Minibatch loss at step 7500: 1.539744\n",
      "Minibatch single digit accuracy: 86.7%\n",
      "Minibatch image accuracy: 81.2%\n",
      "Validation single digit accuracy: 83.6%\n",
      "Validation image accuracy: 74.5%\n",
      "Minibatch loss at step 8000: 1.200860\n",
      "Minibatch single digit accuracy: 92.3%\n",
      "Minibatch image accuracy: 87.5%\n",
      "Validation single digit accuracy: 83.8%\n",
      "Validation image accuracy: 74.7%\n",
      "Minibatch loss at step 8500: 1.881015\n",
      "Minibatch single digit accuracy: 84.4%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 83.6%\n",
      "Validation image accuracy: 74.3%\n",
      "Minibatch loss at step 9000: 1.979492\n",
      "Minibatch single digit accuracy: 85.6%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 83.6%\n",
      "Validation image accuracy: 74.4%\n",
      "Minibatch loss at step 9500: 1.553418\n",
      "Minibatch single digit accuracy: 94.2%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 83.8%\n",
      "Validation image accuracy: 74.7%\n",
      "Minibatch loss at step 10000: 1.535608\n",
      "Minibatch single digit accuracy: 88.8%\n",
      "Minibatch image accuracy: 79.7%\n",
      "Validation single digit accuracy: 83.7%\n",
      "Validation image accuracy: 74.5%\n",
      "Test single digit accuracy: 83.7%\n",
      "Test image accuracy: 74.9%\n",
      "Model saved in file: 3cnn.ckpt\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    \n",
    "    # If you want to restore model\n",
    "    saver.restore(session, \"3cnn.ckpt\")\n",
    "    print(\"Model restored!\")\n",
    "\n",
    "#     tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 1e-3}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch single digit accuracy: %.1f%%' % accuracy_single(predictions, batch_labels))\n",
    "            print('Minibatch image accuracy: %.1f%%' % accuracy_multi(predictions, batch_labels))\n",
    "            print('Validation single digit accuracy: %.1f%%' % accuracy_single(valid_prediction.eval(), valid_labels))\n",
    "            print('Validation image accuracy: %.1f%%' % accuracy_multi(valid_prediction.eval(), valid_labels))\n",
    "            \n",
    "    print('Test single digit accuracy: %.1f%%' % accuracy_single(test_prediction.eval(), test_labels))\n",
    "    print('Test image accuracy: %.1f%%' % accuracy_multi(test_prediction.eval(), test_labels))\n",
    "    \n",
    "    save_path = saver.save(session, \"3cnn.ckpt\")\n",
    "    print('Model saved in file: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add one conv layer - (Abandoned.  RAM runs out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5 # conv kernel size\n",
    "patch_size2 = 5\n",
    "depth1 = 16\n",
    "depth2 = 32\n",
    "# depth3 = 48\n",
    "depth3 = 128\n",
    "num_hidden = 64\n",
    "\n",
    "image_size = 32\n",
    "num_labels = 11 \n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    def get_weight_variable(name, shape):\n",
    "        return tf.get_variable(name, shape=shape, initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(1.0, shape = shape)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def conv2d(data, weight):\n",
    "        # strides [1, x_movement, y_movement, 1]\n",
    "        return tf.nn.conv2d(data, weight, strides = [1, 1, 1, 1], padding = 'VALID')\n",
    "\n",
    "    def max_pooling(data, strides):\n",
    "        return tf.nn.max_pool(data, ksize = [1, 2, 2, 1], strides = strides, padding = 'SAME')\n",
    "    \n",
    "    def get_label_wb(weight_name):\n",
    "        weights = tf.get_variable(weight_name, shape=[num_hidden, num_labels],\\\n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "        return weights, biases \n",
    "    \n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 6))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    \n",
    "    # Varibles\n",
    "    # conv1 layer 1\n",
    "    layer1_weights = get_weight_variable('CNN_W1', [patch_size, patch_size, num_channels, depth1])\n",
    "    layer1_biases = bias_variable([depth1]) # 16\n",
    "    # conv2 layer 2\n",
    "    layer2_weights = get_weight_variable('CNN_W2', [patch_size, patch_size, depth1, depth2])\n",
    "    layer2_biases = bias_variable([depth2]) # 32\n",
    "    # conv3 layer 3\n",
    "    layer3_weights = get_weight_variable('CNN_W3', [patch_size2, patch_size2, depth2, depth3])\n",
    "    layer3_biases = bias_variable([depth3]) # 64\n",
    "#     # conv4 layer 4\n",
    "#     layer4_weights = get_weight_variable('CNN_W4', [patch_size2, patch_size2, depth3, depth4])\n",
    "#     layer4_biases = bias_variable([depth4]) # 64\n",
    "    \n",
    "    # func1 layer 5\n",
    "    layer5_weights = get_weight_variable('FC_W1',[1152, num_hidden])\n",
    "    layer5_biases = bias_variable([num_hidden])\n",
    "    \n",
    "    # locally connected layers\n",
    "    s1_w, s1_b = get_label_wb('S1_W')\n",
    "    s2_w, s2_b = get_label_wb('S2_W')\n",
    "    s3_w, s3_b = get_label_wb('S3_W')\n",
    "    s4_w, s4_b = get_label_wb('S4_W')\n",
    "    s5_w, s5_b = get_label_wb('S5_W')\n",
    "    \n",
    "    sw = [s1_w, s2_w, s3_w, s4_w, s5_w]\n",
    "    \n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    \n",
    "    def model(dataset, keep_prob, keep_prob2):\n",
    "        # conv1 layer 1\n",
    "        hidden1 = tf.nn.relu(conv2d(dataset, layer1_weights) + layer1_biases) # 32 * 32 * depth1\n",
    "        hidden1 = tf.nn.local_response_normalization(hidden1)\n",
    "        pool1 = max_pooling(hidden1, [1, 2, 2, 1]) # 16 * 16 * depth1\n",
    "        \n",
    "        # conv2 layer 2\n",
    "        hidden2 = tf.nn.relu(conv2d(pool1, layer2_weights) + layer2_biases) # 16 * 16 * depth2\n",
    "        hidden2 = tf.nn.local_response_normalization(hidden2)\n",
    "        pool2 = max_pooling(hidden2, [1, 1, 1, 1]) # 8 * 8 * depth2\n",
    "        pool2 = tf.nn.dropout(pool2, keep_prob2)\n",
    "        \n",
    "        # conv3 layer 3\n",
    "        hidden3 = tf.nn.relu(conv2d(pool2, layer3_weights) + layer3_biases) # 8 * 8 * depth3\n",
    "        hidden3 = tf.nn.local_response_normalization(hidden3)\n",
    "        pool3 = max_pooling(hidden3, [1, 2, 2, 1]) # 4 * 4 * depth3\n",
    "#         pool3 = tf.nn.dropout(pool3, keep_prob2)\n",
    "        \n",
    "#         # conv3 layer 3\n",
    "#         hidden4 = tf.nn.relu(conv2d(pool3, layer4_weights) + layer4_biases) # 8 * 8 * depth3\n",
    "#         hidden4 = tf.nn.local_response_normalization(hidden4)\n",
    "#         pool4 = max_pooling(hidden4, [1, 2, 2, 1]) # 4 * 4 * depth3\n",
    "#         pool4 = tf.nn.dropout(pool4, keep_prob2)\n",
    "        \n",
    "        shape = pool3.get_shape().as_list()\n",
    "        pool3_flat = tf.reshape(pool3, [shape[0], shape[1] * shape[2] * shape[3]]) # 1024\n",
    "        \n",
    "        # func1 layer 4\n",
    "        hidden5 = tf.nn.relu(tf.matmul(pool3_flat, layer5_weights) + layer5_biases)\n",
    "        hidden5_drop = tf.nn.dropout(hidden5, keep_prob)\n",
    "\n",
    "        logits_1 = tf.matmul(hidden5_drop, s1_w) + s1_b\n",
    "        logits_2 = tf.matmul(hidden5_drop, s2_w) + s2_b\n",
    "        logits_3 = tf.matmul(hidden5_drop, s3_w) + s3_b\n",
    "        logits_4 = tf.matmul(hidden5_drop, s4_w) + s4_b\n",
    "        logits_5 = tf.matmul(hidden5_drop, s5_w) + s5_b\n",
    "        \n",
    "        return [logits_1, logits_2, logits_3, logits_4, logits_5]\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset, 0.5, 0.8)\n",
    "    \n",
    "    loss_per_digit = [tf.reduce_mean(\n",
    "                        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                            logits[i],\n",
    "                            tf_train_labels[:,i+1]\n",
    "                        )) + beta_regul * tf.nn.l2_loss(sw[i])\n",
    "                       for i in range(5)]\n",
    "    \n",
    "    loss = tf.add_n(loss_per_digit)\n",
    "\n",
    "    # Optimizer.\n",
    "    learning_rate = tf.train.exponential_decay(0.001, global_step, 1000, 0.90, staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    def prediction_softmax(dataset):\n",
    "        prediction = tf.pack([\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[0]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[1]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[2]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[3]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[4])])\n",
    "        return prediction\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = prediction_softmax(tf_train_dataset)\n",
    "    valid_prediction = prediction_softmax(tf_valid_dataset)             \n",
    "    test_prediction = prediction_softmax(tf_test_dataset)\n",
    "    \n",
    "    # Save Model \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 21.580215\n",
      "Minibatch single digit accuracy: 2.7%\n",
      "Minibatch image accuracy: 0.0%\n",
      "Validation single digit accuracy: 6.9%\n",
      "Validation image accuracy: 0.0%\n",
      "Minibatch loss at step 500: 6.046764\n",
      "Minibatch single digit accuracy: 12.4%\n",
      "Minibatch image accuracy: 3.1%\n",
      "Validation single digit accuracy: 19.1%\n",
      "Validation image accuracy: 3.6%\n",
      "Minibatch loss at step 1000: 5.019938\n",
      "Minibatch single digit accuracy: 33.6%\n",
      "Minibatch image accuracy: 10.9%\n",
      "Validation single digit accuracy: 33.9%\n",
      "Validation image accuracy: 13.1%\n",
      "Minibatch loss at step 1500: 4.056178\n",
      "Minibatch single digit accuracy: 54.3%\n",
      "Minibatch image accuracy: 34.4%\n",
      "Validation single digit accuracy: 48.2%\n",
      "Validation image accuracy: 28.1%\n",
      "Minibatch loss at step 2000: 3.900603\n",
      "Minibatch single digit accuracy: 50.7%\n",
      "Minibatch image accuracy: 34.4%\n",
      "Validation single digit accuracy: 56.2%\n",
      "Validation image accuracy: 37.0%\n",
      "Minibatch loss at step 2500: 3.121350\n",
      "Minibatch single digit accuracy: 67.2%\n",
      "Minibatch image accuracy: 45.3%\n",
      "Validation single digit accuracy: 61.0%\n",
      "Validation image accuracy: 43.6%\n",
      "Minibatch loss at step 3000: 2.897475\n",
      "Minibatch single digit accuracy: 67.6%\n",
      "Minibatch image accuracy: 60.9%\n",
      "Validation single digit accuracy: 65.7%\n",
      "Validation image accuracy: 50.5%\n",
      "Minibatch loss at step 3500: 2.975567\n",
      "Minibatch single digit accuracy: 67.1%\n",
      "Minibatch image accuracy: 51.6%\n",
      "Validation single digit accuracy: 70.5%\n",
      "Validation image accuracy: 56.6%\n",
      "Minibatch loss at step 4000: 2.281278\n",
      "Minibatch single digit accuracy: 79.0%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 71.6%\n",
      "Validation image accuracy: 58.0%\n",
      "Minibatch loss at step 4500: 2.070471\n",
      "Minibatch single digit accuracy: 77.9%\n",
      "Minibatch image accuracy: 67.2%\n",
      "Validation single digit accuracy: 73.8%\n",
      "Validation image accuracy: 61.0%\n",
      "Minibatch loss at step 5000: 2.151306\n",
      "Minibatch single digit accuracy: 74.3%\n",
      "Minibatch image accuracy: 60.9%\n",
      "Validation single digit accuracy: 74.4%\n",
      "Validation image accuracy: 61.4%\n",
      "Minibatch loss at step 5500: 1.939853\n",
      "Minibatch single digit accuracy: 78.5%\n",
      "Minibatch image accuracy: 59.4%\n",
      "Validation single digit accuracy: 75.0%\n",
      "Validation image accuracy: 62.2%\n",
      "Minibatch loss at step 6000: 2.011651\n",
      "Minibatch single digit accuracy: 79.3%\n",
      "Minibatch image accuracy: 65.6%\n",
      "Validation single digit accuracy: 76.3%\n",
      "Validation image accuracy: 63.9%\n",
      "Minibatch loss at step 6500: 1.661243\n",
      "Minibatch single digit accuracy: 83.9%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 77.9%\n",
      "Validation image accuracy: 65.4%\n",
      "Minibatch loss at step 7000: 2.375058\n",
      "Minibatch single digit accuracy: 76.0%\n",
      "Minibatch image accuracy: 64.1%\n",
      "Validation single digit accuracy: 78.1%\n",
      "Validation image accuracy: 66.7%\n",
      "Minibatch loss at step 7500: 1.886878\n",
      "Minibatch single digit accuracy: 80.4%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 78.1%\n",
      "Validation image accuracy: 66.8%\n",
      "Minibatch loss at step 8000: 1.759828\n",
      "Minibatch single digit accuracy: 81.8%\n",
      "Minibatch image accuracy: 71.9%\n",
      "Validation single digit accuracy: 78.3%\n",
      "Validation image accuracy: 67.0%\n",
      "Minibatch loss at step 8500: 2.208157\n",
      "Minibatch single digit accuracy: 81.0%\n",
      "Minibatch image accuracy: 71.9%\n",
      "Validation single digit accuracy: 79.0%\n",
      "Validation image accuracy: 68.0%\n",
      "Minibatch loss at step 9000: 2.297939\n",
      "Minibatch single digit accuracy: 79.1%\n",
      "Minibatch image accuracy: 71.9%\n",
      "Validation single digit accuracy: 79.3%\n",
      "Validation image accuracy: 68.2%\n",
      "Minibatch loss at step 9500: 1.511883\n",
      "Minibatch single digit accuracy: 91.4%\n",
      "Minibatch image accuracy: 84.4%\n",
      "Validation single digit accuracy: 79.3%\n",
      "Validation image accuracy: 68.3%\n",
      "Minibatch loss at step 10000: 1.828559\n",
      "Minibatch single digit accuracy: 85.1%\n",
      "Minibatch image accuracy: 71.9%\n",
      "Validation single digit accuracy: 79.8%\n",
      "Validation image accuracy: 68.9%\n",
      "Test single digit accuracy: 80.6%\n",
      "Test image accuracy: 70.6%\n",
      "Model saved in file: 5cnn.ckpt\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    \n",
    "#     save_path = saver.save(session, \"CNN5.ckpt\")\n",
    "#     print(\"Model restored to:\", save_path)  \n",
    "    \n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 1e-3}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch single digit accuracy: %.1f%%' % accuracy_single(predictions, batch_labels))\n",
    "            print('Minibatch image accuracy: %.1f%%' % accuracy_multi(predictions, batch_labels))\n",
    "            print('Validation single digit accuracy: %.1f%%' % accuracy_single(valid_prediction.eval(), valid_labels))\n",
    "            print('Validation image accuracy: %.1f%%' % accuracy_multi(valid_prediction.eval(), valid_labels))\n",
    "            \n",
    "    print('Test single digit accuracy: %.1f%%' % accuracy_single(test_prediction.eval(), test_labels))\n",
    "    print('Test image accuracy: %.1f%%' % accuracy_multi(test_prediction.eval(), test_labels))\n",
    "    \n",
    "    save_path = saver.save(session, \"5cnn.ckpt\")\n",
    "    print('Model saved in file: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored!\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1.978281\n",
      "Minibatch single digit accuracy: 85.0%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 79.8%\n",
      "Validation image accuracy: 68.9%\n",
      "Minibatch loss at step 500: 2.169738\n",
      "Minibatch single digit accuracy: 86.9%\n",
      "Minibatch image accuracy: 79.7%\n",
      "Validation single digit accuracy: 80.0%\n",
      "Validation image accuracy: 69.2%\n",
      "Minibatch loss at step 1000: 2.131892\n",
      "Minibatch single digit accuracy: 83.2%\n",
      "Minibatch image accuracy: 75.0%\n",
      "Validation single digit accuracy: 80.0%\n",
      "Validation image accuracy: 69.5%\n",
      "Minibatch loss at step 1500: 1.469676\n",
      "Minibatch single digit accuracy: 86.4%\n",
      "Minibatch image accuracy: 79.7%\n",
      "Validation single digit accuracy: 79.9%\n",
      "Validation image accuracy: 69.7%\n",
      "Minibatch loss at step 2000: 2.054354\n",
      "Minibatch single digit accuracy: 85.2%\n",
      "Minibatch image accuracy: 81.2%\n",
      "Validation single digit accuracy: 80.4%\n",
      "Validation image accuracy: 70.3%\n",
      "Minibatch loss at step 2500: 1.332862\n",
      "Minibatch single digit accuracy: 94.9%\n",
      "Minibatch image accuracy: 87.5%\n",
      "Validation single digit accuracy: 80.3%\n",
      "Validation image accuracy: 69.9%\n",
      "Minibatch loss at step 3000: 2.060459\n",
      "Minibatch single digit accuracy: 82.7%\n",
      "Minibatch image accuracy: 76.6%\n",
      "Validation single digit accuracy: 80.3%\n",
      "Validation image accuracy: 70.2%\n",
      "Minibatch loss at step 3500: 1.636135\n",
      "Minibatch single digit accuracy: 87.0%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 80.6%\n",
      "Validation image accuracy: 70.2%\n",
      "Minibatch loss at step 4000: 1.101616\n",
      "Minibatch single digit accuracy: 91.6%\n",
      "Minibatch image accuracy: 87.5%\n",
      "Validation single digit accuracy: 80.5%\n",
      "Validation image accuracy: 70.5%\n",
      "Minibatch loss at step 4500: 1.563582\n",
      "Minibatch single digit accuracy: 88.6%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 81.0%\n",
      "Validation image accuracy: 71.1%\n",
      "Minibatch loss at step 5000: 1.462399\n",
      "Minibatch single digit accuracy: 89.3%\n",
      "Minibatch image accuracy: 79.7%\n",
      "Validation single digit accuracy: 80.9%\n",
      "Validation image accuracy: 71.2%\n",
      "Minibatch loss at step 5500: 1.287081\n",
      "Minibatch single digit accuracy: 91.9%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 81.2%\n",
      "Validation image accuracy: 71.2%\n",
      "Minibatch loss at step 6000: 1.548199\n",
      "Minibatch single digit accuracy: 88.3%\n",
      "Minibatch image accuracy: 81.2%\n",
      "Validation single digit accuracy: 80.7%\n",
      "Validation image accuracy: 70.7%\n",
      "Minibatch loss at step 6500: 1.273672\n",
      "Minibatch single digit accuracy: 89.5%\n",
      "Minibatch image accuracy: 87.5%\n",
      "Validation single digit accuracy: 81.4%\n",
      "Validation image accuracy: 71.2%\n",
      "Minibatch loss at step 7000: 2.028769\n",
      "Minibatch single digit accuracy: 82.5%\n",
      "Minibatch image accuracy: 75.0%\n",
      "Validation single digit accuracy: 81.4%\n",
      "Validation image accuracy: 71.5%\n",
      "Minibatch loss at step 7500: 1.574272\n",
      "Minibatch single digit accuracy: 84.6%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 81.1%\n",
      "Validation image accuracy: 71.3%\n",
      "Minibatch loss at step 8000: 1.520929\n",
      "Minibatch single digit accuracy: 86.7%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 81.4%\n",
      "Validation image accuracy: 71.5%\n",
      "Minibatch loss at step 8500: 1.927362\n",
      "Minibatch single digit accuracy: 83.7%\n",
      "Minibatch image accuracy: 76.6%\n",
      "Validation single digit accuracy: 81.4%\n",
      "Validation image accuracy: 71.4%\n",
      "Minibatch loss at step 9000: 1.756405\n",
      "Minibatch single digit accuracy: 87.1%\n",
      "Minibatch image accuracy: 81.2%\n",
      "Validation single digit accuracy: 81.6%\n",
      "Validation image accuracy: 71.8%\n",
      "Minibatch loss at step 9500: 1.507004\n",
      "Minibatch single digit accuracy: 93.5%\n",
      "Minibatch image accuracy: 87.5%\n",
      "Validation single digit accuracy: 81.6%\n",
      "Validation image accuracy: 71.8%\n",
      "Minibatch loss at step 10000: 1.721653\n",
      "Minibatch single digit accuracy: 88.1%\n",
      "Minibatch image accuracy: 75.0%\n",
      "Validation single digit accuracy: 81.8%\n",
      "Validation image accuracy: 71.8%\n",
      "Test single digit accuracy: 82.3%\n",
      "Test image accuracy: 72.5%\n",
      "Model saved in file: 5cnn.ckpt\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    \n",
    "    # If you want to restore model\n",
    "    saver.restore(session, \"5cnn.ckpt\")\n",
    "    print(\"Model restored!\")\n",
    "    \n",
    "#     tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 1e-3}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch single digit accuracy: %.1f%%' % accuracy_single(predictions, batch_labels))\n",
    "            print('Minibatch image accuracy: %.1f%%' % accuracy_multi(predictions, batch_labels))\n",
    "            print('Validation single digit accuracy: %.1f%%' % accuracy_single(valid_prediction.eval(), valid_labels))\n",
    "            print('Validation image accuracy: %.1f%%' % accuracy_multi(valid_prediction.eval(), valid_labels))\n",
    "            \n",
    "    print('Test single digit accuracy: %.1f%%' % accuracy_single(test_prediction.eval(), test_labels))\n",
    "    print('Test image accuracy: %.1f%%' % accuracy_multi(test_prediction.eval(), test_labels))\n",
    "    \n",
    "    save_path = saver.save(session, \"5cnn.ckpt\")\n",
    "    print('Model saved in file: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
